{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a159229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.api import add_constant\n",
    "from numpy.linalg import lstsq\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skglm import GeneralizedLinearEstimator\n",
    "from skglm.penalties import SCAD\n",
    "\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597c3daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df69260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 3\n",
    "GF = np.array((1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6b7b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>exper</th>\n",
       "      <th>hours</th>\n",
       "      <th>married</th>\n",
       "      <th>union</th>\n",
       "      <th>expersq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nr</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">13</th>\n",
       "      <th>1980</th>\n",
       "      <td>1</td>\n",
       "      <td>2672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>2</td>\n",
       "      <td>2320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>3</td>\n",
       "      <td>2940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>4</td>\n",
       "      <td>2960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>5</td>\n",
       "      <td>3071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">12548</th>\n",
       "      <th>1983</th>\n",
       "      <td>8</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>9</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>10</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>11</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>12</td>\n",
       "      <td>3380</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4360 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            exper  hours  married  union  expersq\n",
       "nr    year                                       \n",
       "13    1980      1   2672        0      0        1\n",
       "      1981      2   2320        0      1        4\n",
       "      1982      3   2940        0      0        9\n",
       "      1983      4   2960        0      0       16\n",
       "      1984      5   3071        0      0       25\n",
       "...           ...    ...      ...    ...      ...\n",
       "12548 1983      8   2080        1      0       64\n",
       "      1984      9   2080        1      1       81\n",
       "      1985     10   2080        1      0      100\n",
       "      1986     11   2080        1      1      121\n",
       "      1987     12   3380        1      1      144\n",
       "\n",
       "[4360 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nr     year\n",
       "13     1980    1.197540\n",
       "       1981    1.853060\n",
       "       1982    1.344462\n",
       "       1983    1.433213\n",
       "       1984    1.568125\n",
       "                 ...   \n",
       "12548  1983    1.591879\n",
       "       1984    1.212543\n",
       "       1985    1.765962\n",
       "       1986    1.745894\n",
       "       1987    1.466543\n",
       "Name: lwage, Length: 4360, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from linearmodels.datasets import wage_panel\n",
    "\n",
    "wage_panel_df = wage_panel.load()\n",
    "\n",
    "wage_panel_df.set_index([\"nr\", \"year\"], inplace=True)\n",
    "y = wage_panel_df[\"lwage\"]\n",
    "x = wage_panel_df.drop(columns=[\"occupation\", \"lwage\", \"black\", \"hisp\", \"educ\"])\n",
    "display(x)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a6f698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 8, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = x.index.get_level_values(0).nunique()\n",
    "T = x.index.get_level_values(1).nunique()\n",
    "K = x.shape[1]\n",
    "N, T, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14deab7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[   1, 2672,    0,    0,    1],\n",
       "         [   2, 2320,    0,    1,    4],\n",
       "         [   3, 2940,    0,    0,    9],\n",
       "         ...,\n",
       "         [   6, 2864,    0,    0,   36],\n",
       "         [   7, 2994,    0,    0,   49],\n",
       "         [   8, 2640,    0,    0,   64]],\n",
       " \n",
       "        [[   4, 2484,    0,    0,   16],\n",
       "         [   5, 2804,    0,    0,   25],\n",
       "         [   6, 2530,    0,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2164,    0,    0,   81],\n",
       "         [  10, 2749,    0,    0,  100],\n",
       "         [  11, 2476,    0,    0,  121]],\n",
       " \n",
       "        [[   4, 2332,    1,    0,   16],\n",
       "         [   5, 2116,    1,    0,   25],\n",
       "         [   6, 2500,    1,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2340,    1,    0,   81],\n",
       "         [  10, 2340,    1,    0,  100],\n",
       "         [  11, 2340,    1,    0,  121]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   4, 2008,    1,    0,   16],\n",
       "         [   5, 3190,    0,    0,   25],\n",
       "         [   6, 2584,    0,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2290,    1,    0,   81],\n",
       "         [  10, 3151,    1,    0,  100],\n",
       "         [  11, 3276,    1,    0,  121]],\n",
       " \n",
       "        [[   2, 2080,    0,    0,    4],\n",
       "         [   3, 2000,    0,    0,    9],\n",
       "         [   4, 1800,    1,    0,   16],\n",
       "         ...,\n",
       "         [   7, 2080,    1,    0,   49],\n",
       "         [   8, 2080,    1,    0,   64],\n",
       "         [   9, 2080,    1,    0,   81]],\n",
       " \n",
       "        [[   5, 2000,    0,    0,   25],\n",
       "         [   6, 2112,    0,    0,   36],\n",
       "         [   7, 2080,    0,    0,   49],\n",
       "         ...,\n",
       "         [  10, 2080,    1,    0,  100],\n",
       "         [  11, 2080,    1,    1,  121],\n",
       "         [  12, 3380,    1,    1,  144]]]),\n",
       " array([[[ 1.19754  ],\n",
       "         [ 1.85306  ],\n",
       "         [ 1.344462 ],\n",
       "         ...,\n",
       "         [ 1.699891 ],\n",
       "         [-0.7202626],\n",
       "         [ 1.669188 ]],\n",
       " \n",
       "        [[ 1.675962 ],\n",
       "         [ 1.518398 ],\n",
       "         [ 1.559191 ],\n",
       "         ...,\n",
       "         [ 1.608588 ],\n",
       "         [ 1.572385 ],\n",
       "         [ 1.820334 ]],\n",
       " \n",
       "        [[ 1.515963 ],\n",
       "         [ 1.735379 ],\n",
       "         [ 1.631744 ],\n",
       "         ...,\n",
       "         [ 2.266662 ],\n",
       "         [ 2.069944 ],\n",
       "         [ 2.873161 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.9724026],\n",
       "         [ 1.324886 ],\n",
       "         [ 0.962707 ],\n",
       "         ...,\n",
       "         [ 2.037503 ],\n",
       "         [ 1.148221 ],\n",
       "         [ 1.30674  ]],\n",
       " \n",
       "        [[ 1.840042 ],\n",
       "         [ 2.174752 ],\n",
       "         [ 2.122767 ],\n",
       "         ...,\n",
       "         [ 2.207794 ],\n",
       "         [ 2.381883 ],\n",
       "         [ 2.342917 ]],\n",
       " \n",
       "        [[ 1.130545 ],\n",
       "         [ 1.311603 ],\n",
       "         [ 0.8324816],\n",
       "         ...,\n",
       "         [ 1.765962 ],\n",
       "         [ 1.745894 ],\n",
       "         [ 1.466543 ]]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.values.reshape(N, T, K)\n",
    "y = y.values.reshape(N, T, 1)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f49d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x[:30]\n",
    "# y = y[:30]\n",
    "# N = 30\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eba2b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.000e+00, 1.000e+00, 2.672e+03, 0.000e+00, 0.000e+00,\n",
       "         1.000e+00],\n",
       "        [1.000e+00, 2.000e+00, 2.320e+03, 0.000e+00, 1.000e+00,\n",
       "         4.000e+00],\n",
       "        [1.000e+00, 3.000e+00, 2.940e+03, 0.000e+00, 0.000e+00,\n",
       "         9.000e+00],\n",
       "        ...,\n",
       "        [1.000e+00, 6.000e+00, 2.864e+03, 0.000e+00, 0.000e+00,\n",
       "         3.600e+01],\n",
       "        [1.000e+00, 7.000e+00, 2.994e+03, 0.000e+00, 0.000e+00,\n",
       "         4.900e+01],\n",
       "        [1.000e+00, 8.000e+00, 2.640e+03, 0.000e+00, 0.000e+00,\n",
       "         6.400e+01]],\n",
       "\n",
       "       [[1.000e+00, 4.000e+00, 2.484e+03, 0.000e+00, 0.000e+00,\n",
       "         1.600e+01],\n",
       "        [1.000e+00, 5.000e+00, 2.804e+03, 0.000e+00, 0.000e+00,\n",
       "         2.500e+01],\n",
       "        [1.000e+00, 6.000e+00, 2.530e+03, 0.000e+00, 0.000e+00,\n",
       "         3.600e+01],\n",
       "        ...,\n",
       "        [1.000e+00, 9.000e+00, 2.164e+03, 0.000e+00, 0.000e+00,\n",
       "         8.100e+01],\n",
       "        [1.000e+00, 1.000e+01, 2.749e+03, 0.000e+00, 0.000e+00,\n",
       "         1.000e+02],\n",
       "        [1.000e+00, 1.100e+01, 2.476e+03, 0.000e+00, 0.000e+00,\n",
       "         1.210e+02]],\n",
       "\n",
       "       [[1.000e+00, 4.000e+00, 2.332e+03, 1.000e+00, 0.000e+00,\n",
       "         1.600e+01],\n",
       "        [1.000e+00, 5.000e+00, 2.116e+03, 1.000e+00, 0.000e+00,\n",
       "         2.500e+01],\n",
       "        [1.000e+00, 6.000e+00, 2.500e+03, 1.000e+00, 0.000e+00,\n",
       "         3.600e+01],\n",
       "        ...,\n",
       "        [1.000e+00, 9.000e+00, 2.340e+03, 1.000e+00, 0.000e+00,\n",
       "         8.100e+01],\n",
       "        [1.000e+00, 1.000e+01, 2.340e+03, 1.000e+00, 0.000e+00,\n",
       "         1.000e+02],\n",
       "        [1.000e+00, 1.100e+01, 2.340e+03, 1.000e+00, 0.000e+00,\n",
       "         1.210e+02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.000e+00, 4.000e+00, 2.008e+03, 1.000e+00, 0.000e+00,\n",
       "         1.600e+01],\n",
       "        [1.000e+00, 5.000e+00, 3.190e+03, 0.000e+00, 0.000e+00,\n",
       "         2.500e+01],\n",
       "        [1.000e+00, 6.000e+00, 2.584e+03, 0.000e+00, 0.000e+00,\n",
       "         3.600e+01],\n",
       "        ...,\n",
       "        [1.000e+00, 9.000e+00, 2.290e+03, 1.000e+00, 0.000e+00,\n",
       "         8.100e+01],\n",
       "        [1.000e+00, 1.000e+01, 3.151e+03, 1.000e+00, 0.000e+00,\n",
       "         1.000e+02],\n",
       "        [1.000e+00, 1.100e+01, 3.276e+03, 1.000e+00, 0.000e+00,\n",
       "         1.210e+02]],\n",
       "\n",
       "       [[1.000e+00, 2.000e+00, 2.080e+03, 0.000e+00, 0.000e+00,\n",
       "         4.000e+00],\n",
       "        [1.000e+00, 3.000e+00, 2.000e+03, 0.000e+00, 0.000e+00,\n",
       "         9.000e+00],\n",
       "        [1.000e+00, 4.000e+00, 1.800e+03, 1.000e+00, 0.000e+00,\n",
       "         1.600e+01],\n",
       "        ...,\n",
       "        [1.000e+00, 7.000e+00, 2.080e+03, 1.000e+00, 0.000e+00,\n",
       "         4.900e+01],\n",
       "        [1.000e+00, 8.000e+00, 2.080e+03, 1.000e+00, 0.000e+00,\n",
       "         6.400e+01],\n",
       "        [1.000e+00, 9.000e+00, 2.080e+03, 1.000e+00, 0.000e+00,\n",
       "         8.100e+01]],\n",
       "\n",
       "       [[1.000e+00, 5.000e+00, 2.000e+03, 0.000e+00, 0.000e+00,\n",
       "         2.500e+01],\n",
       "        [1.000e+00, 6.000e+00, 2.112e+03, 0.000e+00, 0.000e+00,\n",
       "         3.600e+01],\n",
       "        [1.000e+00, 7.000e+00, 2.080e+03, 0.000e+00, 0.000e+00,\n",
       "         4.900e+01],\n",
       "        ...,\n",
       "        [1.000e+00, 1.000e+01, 2.080e+03, 1.000e+00, 0.000e+00,\n",
       "         1.000e+02],\n",
       "        [1.000e+00, 1.100e+01, 2.080e+03, 1.000e+00, 1.000e+00,\n",
       "         1.210e+02],\n",
       "        [1.000e+00, 1.200e+01, 3.380e+03, 1.000e+00, 1.000e+00,\n",
       "         1.440e+02]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.concatenate((np.ones((N, T, 1)), x), axis=2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674f9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.77913967e+00],\n",
       "        [-9.72149236e-03],\n",
       "        [-9.00525904e-05],\n",
       "        [ 1.94730981e-01],\n",
       "        [ 1.85149256e-01],\n",
       "        [-8.10189556e-04]]),\n",
       " array([1, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 1, 0, 0,\n",
       "        0, 2, 0, 0, 2, 1, 1, 0, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 1, 2, 0, 2,\n",
       "        0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 2, 2, 0, 0, 1, 0, 2, 2, 0, 1,\n",
       "        0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 2, 2, 0, 0,\n",
       "        0, 0, 2, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0,\n",
       "        2, 1, 2, 2, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2,\n",
       "        1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 2, 0, 0, 2, 0,\n",
       "        0, 2, 0, 2, 0, 2, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 2, 0, 0, 2, 1, 0, 2, 1, 0, 1, 1, 2,\n",
       "        0, 1, 0, 0, 2, 2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 2, 1, 0, 1, 1, 0, 0,\n",
       "        0, 2, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 0, 1, 1, 2, 0,\n",
       "        1, 2, 2, 0, 2, 2, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 0,\n",
       "        0, 0, 0, 2, 1, 0, 1, 0, 1, 0, 2, 0, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1,\n",
       "        1, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 1, 2, 2, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0,\n",
       "        2, 0, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0,\n",
       "        2, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2,\n",
       "        1, 0, 1, 2, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 2, 2, 1, 0, 0, 0,\n",
       "        2, 2, 1, 0, 1, 0, 1, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2,\n",
       "        0, 1, 1, 2, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 1, 1, 0, 2, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 2, 1, 2, 2, 2, 0, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 2, 2, 0, 2, 2, 1, 2, 2, 1, 2, 2, 2, 0, 1, 2,\n",
       "        0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 2, 2, 2, 2, 1]),\n",
       " array([[-1.13399922,  0.3406264 , -2.54840346],\n",
       "        [-1.4511238 , -0.1766671 , -0.09599861],\n",
       "        [-0.78043172, -0.29475244,  0.12661425],\n",
       "        [-0.33042632, -0.54041796,  0.20247886],\n",
       "        [ 0.43317791, -1.98980123,  0.38177815],\n",
       "        [ 0.79601967,  0.17678083,  0.47125485],\n",
       "        [ 1.11887217,  1.68796793,  0.69625227],\n",
       "        [ 1.34791132,  0.79626357,  0.7660237 ]]),\n",
       " array([[-0.18049147,  0.08229769,  0.39686253, ...,  0.18718244,\n",
       "          0.0970544 ,  0.11121306],\n",
       "        [-0.45961856,  0.03258844,  0.07862293, ..., -0.11290516,\n",
       "          0.07535269,  0.14999859],\n",
       "        [-0.03693298,  0.03638452,  0.30389003, ...,  0.20867712,\n",
       "          0.10712949,  0.0813496 ]]),\n",
       " np.float64(850.779395856588))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_factors_initial(y, GF, T):\n",
    "    y_squeezed = np.squeeze(y).T\n",
    "    pca = PCA(n_components=GF.sum())\n",
    "    U = pca.fit_transform(y_squeezed)/pca.singular_values_\n",
    "    F = np.sqrt(T) * U\n",
    "    Lambda = F.T @ y_squeezed / T\n",
    "\n",
    "    return F, Lambda\n",
    "\n",
    "\n",
    "def _get_factors(y, x, beta, g, G, GF, T):\n",
    "    y_squeezed = np.squeeze(y - x @ beta).T\n",
    "\n",
    "    F = np.zeros((T, GF.sum()))\n",
    "    Lambda = np.zeros((GF.sum(), y_squeezed.shape[1]))\n",
    "\n",
    "    for i in range(G):\n",
    "        y_squeezed_partial = np.atleast_2d(np.squeeze(y[g==i] - x[g==i] @ beta).T)\n",
    "\n",
    "        pca = PCA(n_components=GF[i])\n",
    "        U = pca.fit_transform(y_squeezed_partial) / pca.singular_values_\n",
    "\n",
    "        F_partial = np.sqrt(T) * U\n",
    "        F[:, GF[:i].sum():GF[:i+1].sum()] = F_partial\n",
    "\n",
    "        Lambda_partial = F_partial.T @ y_squeezed / T\n",
    "        Lambda[GF[:i].sum():GF[:i+1].sum(), :] = Lambda_partial\n",
    "\n",
    "    return F, Lambda\n",
    "\n",
    "\n",
    "def _get_clusters_initial(Lambda, G, GF):\n",
    "    # FIXME this code is very bad, but it works\n",
    "    while True:\n",
    "        km = KMeans(n_clusters=G)\n",
    "        g = km.fit_predict(Lambda.T)\n",
    "\n",
    "        counts = np.bincount(g, minlength=G)\n",
    "        if np.all(counts >= (GF + 1)):\n",
    "            break\n",
    "\n",
    "    return g\n",
    "\n",
    "def _get_cluster_id(G, GF):\n",
    "    cluster_id = np.zeros(GF.sum(), dtype=np.int8)\n",
    "    for i in range(G):\n",
    "        cluster_id[GF[:i].sum() : GF[: i + 1].sum()] = i\n",
    "    return cluster_id\n",
    "\n",
    "# FIXME this code should be modified s.t. cannot return groups less than size\n",
    "# GF[i]\n",
    "def _get_clusters(y, x, beta, Lambda, g, G, F, GF, N, T):\n",
    "    y_star = y - x @ beta\n",
    "    res = np.zeros((N, T, G))\n",
    "    for i in range(G):\n",
    "        # TODO check if this is correct\n",
    "        # But I think so\n",
    "        res[:,:,i] = y_star.reshape(N, -1) - (F[:, GF[:i].sum():GF[: i + 1].sum()] @ Lambda[GF[:i].sum():GF[: i + 1].sum(), :]).T\n",
    "    res_per_grouping = (res ** 2).sum(axis=1)\n",
    "    g = res_per_grouping.argmin(axis=1)\n",
    "\n",
    "    # Count size of each group\n",
    "    counts = np.bincount(g, minlength=G)\n",
    "\n",
    "    # Ensure minimum group sizes (GF[i] + 1)\n",
    "    min_sizes = GF + 1\n",
    "\n",
    "    # Check if any group is below minimum size\n",
    "    while np.any(counts < min_sizes):\n",
    "        # Find the most deficient group\n",
    "        target_group = np.argmin(counts - min_sizes)\n",
    "        needed = min_sizes[target_group] - counts[target_group]\n",
    "\n",
    "        if needed <= 0:\n",
    "            continue  # This group already meets its minimum\n",
    "\n",
    "        # Find elements not in this group\n",
    "        non_target_indices = np.where(g != target_group)[0]\n",
    "\n",
    "        # Sort by distance to target group\n",
    "        distances = res_per_grouping[non_target_indices, target_group]\n",
    "        closest_indices = non_target_indices[np.argsort(distances)]\n",
    "\n",
    "        # Try to reassign closest elements\n",
    "        reassigned = 0\n",
    "        for idx in closest_indices:\n",
    "            source_group = g[idx]\n",
    "\n",
    "            # Only reassign if source group has enough elements to spare\n",
    "            if counts[source_group] > min_sizes[source_group]:\n",
    "                g[idx] = target_group\n",
    "                counts[source_group] -= 1\n",
    "                counts[target_group] += 1\n",
    "                reassigned += 1\n",
    "\n",
    "                if reassigned >= needed:\n",
    "                    break\n",
    "\n",
    "        # If we couldn't reassign any elements, we're stuck\n",
    "        if reassigned == 0:\n",
    "            raise Exception(\"Cannot satisfy minimum group size constraints.\")\n",
    "\n",
    "    objective_value = res_per_grouping[np.arange(N), g].sum()\n",
    "\n",
    "    return g, objective_value\n",
    "\n",
    "# NOTE this ignores the factor structure\n",
    "def _estimate_beta_initial(y, x, K):\n",
    "    # TODO check if this is correct\n",
    "    beta = lstsq(x.reshape(-1, K), y.reshape(-1, 1), rcond=None)[0]\n",
    "    return beta\n",
    "\n",
    "def _estimate_beta(y, x, g, GF, F, Lambda, K, N, T, G, kappa, gamma):\n",
    "    # TODO check if this is correct\n",
    "    # FIXME no it is not, i is undefined and this formula does not work here\n",
    "    res = np.zeros((N, T, G))\n",
    "    for i in range(G):\n",
    "        # TODO check if this is correct\n",
    "        # But I think so\n",
    "        res[:, :, i] = (\n",
    "            y.reshape(N, -1)\n",
    "            - (F[:, GF[:i].sum() : GF[: i + 1].sum()] @ Lambda[GF[:i].sum() : GF[: i + 1].sum(), :]).T\n",
    "        )\n",
    "\n",
    "    y_star = res[np.arange(N), :, g]\n",
    "    # FIXME the np.arange could be cached or something\n",
    "    if kappa == 0:\n",
    "        beta = lstsq(x.reshape(-1, K), y_star.reshape(-1, 1), rcond=None)[0]\n",
    "        return beta\n",
    "\n",
    "    beta = np.atleast_2d(\n",
    "        GeneralizedLinearEstimator(penalty=SCAD(alpha=kappa, gamma=gamma))\n",
    "        .fit(x.reshape(-1, K), np.squeeze(y_star.reshape(-1, 1)))\n",
    "        .coef_\n",
    "    ).T\n",
    "    return beta\n",
    "\n",
    "    # TODO check if this is correct\n",
    "    # But I think so\n",
    "    # beta = GeneralizedLinearEstimator(penalty=SCAD()).fit(x.reshape(-1, K), y_star.reshape(-1, 1))\n",
    "    # return beta\n",
    "\n",
    "\n",
    "# def _get_initial_values(y, x, G, GF, N, T, K, kappa, gamma):\n",
    "#     F, Lambda = _get_factors(y, GF, N)\n",
    "#     g = _get_clusters(Lambda, G)\n",
    "\n",
    "\n",
    "# FIXME implementation is almost correct, however there are some mistakes chat found\n",
    "# I myself believe that the mistake is how F and Lambda are calculated and how the regroupings are\n",
    "# done based on these estimations. Also there is a mistake in the beta estimation. So essentially\n",
    "# the whole code is wrong.\n",
    "def _grouped_interactive_effects_iteration(y, x, G, GF, N, T, K, kappa, gamma, tol, max_iterations):\n",
    "    last_objective_value = np.inf\n",
    "    F, Lambda = _get_factors_initial(y, GF, T)\n",
    "    g = _get_clusters_initial(Lambda, G, GF)\n",
    "    beta = _estimate_beta_initial(y, x, K)\n",
    "    F, Lambda = _get_factors(y, x, beta, g, G, GF, T)\n",
    "\n",
    "    obj_val_store = 5\n",
    "    objective_values = np.zeros(obj_val_store)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        g, objective_value = _get_clusters(y, x, beta, Lambda, g, G, F, GF, N, T)\n",
    "        F, Lambda = _get_factors(y, x, beta, g, G, GF, T)\n",
    "        beta = _estimate_beta(y, x, g, GF, F, Lambda, K, N, T, G, kappa, gamma)\n",
    "\n",
    "        objective_values[i % obj_val_store] = objective_value\n",
    "        if objective_values.max() - objective_values.min() < tol:\n",
    "            break\n",
    "\n",
    "        last_objective_value = objective_value\n",
    "\n",
    "    return beta, g, F, Lambda, last_objective_value\n",
    "\n",
    "def grouped_interactive_effects(y, x, G, GF=None, kappa=0.0, gamma=3.7, tol=1e-6, gife_iterations=100, max_iterations=1000):\n",
    "    \"\"\"Runs GIFE regression\"\"\"\n",
    "    N, T, K = x.shape\n",
    "    if GF is None:\n",
    "        GF = np.array([1] * G)\n",
    "    else:\n",
    "        GF = np.array(GF)  # Ensures that is an np array\n",
    "\n",
    "    best_objective_value = np.inf\n",
    "    best_g = None\n",
    "    best_beta = None\n",
    "    best_F = None\n",
    "    best_Lambda = None\n",
    "\n",
    "    # FIXME Lamda returns all possible factors and not only the ones that are used\n",
    "\n",
    "    for i in range(gife_iterations):\n",
    "        beta, g, F, Lambda, objective_value = _grouped_interactive_effects_iteration(\n",
    "            y, x, G, GF, N, T, K, kappa, gamma, tol, max_iterations\n",
    "        )\n",
    "\n",
    "        if objective_value < best_objective_value:\n",
    "            best_objective_value = objective_value\n",
    "            best_g = g\n",
    "            best_beta = beta\n",
    "            best_F = F\n",
    "            best_Lambda = Lambda\n",
    "\n",
    "    return best_beta, best_g, best_F, best_Lambda, best_objective_value\n",
    "\n",
    "grouped_interactive_effects(y, x, G, GF, gife_iterations=100, kappa=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5518f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.81998666e+00],\n",
       "        [-9.71977689e-03],\n",
       "        [-9.00524113e-05],\n",
       "        [ 1.94730933e-01],\n",
       "        [ 1.85149034e-01],\n",
       "        [-8.10286021e-04]]),\n",
       " array([0, 1, 1, 1, 2, 2, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 0, 1, 1,\n",
       "        1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 2, 1, 2,\n",
       "        1, 1, 1, 2, 1, 1, 1, 0, 2, 1, 0, 1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0,\n",
       "        1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 0, 2, 1, 1, 2, 2, 1, 1,\n",
       "        1, 1, 2, 1, 1, 0, 1, 2, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 1,\n",
       "        2, 0, 2, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2,\n",
       "        0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 1,\n",
       "        1, 2, 1, 2, 1, 2, 1, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 2, 1, 0, 1, 2, 0, 1, 1, 2, 1, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2,\n",
       "        1, 0, 1, 1, 2, 2, 2, 1, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 0, 1, 1,\n",
       "        1, 2, 1, 1, 2, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 1, 0, 0, 2, 1,\n",
       "        0, 2, 2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1,\n",
       "        1, 1, 1, 2, 0, 1, 0, 1, 0, 1, 2, 1, 2, 0, 0, 1, 1, 0, 0, 0, 2, 0,\n",
       "        0, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1,\n",
       "        2, 1, 0, 2, 2, 1, 2, 0, 2, 2, 1, 2, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1,\n",
       "        2, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2,\n",
       "        0, 1, 0, 2, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 2, 0, 1, 1, 1,\n",
       "        2, 2, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 1, 2,\n",
       "        1, 0, 0, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 0, 0, 1, 2, 1, 1,\n",
       "        0, 0, 1, 1, 1, 0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 0,\n",
       "        1, 1, 1, 0, 0, 1, 1, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 1, 0, 2,\n",
       "        1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0]),\n",
       " array([[ 0.34063014, -1.13399331, -2.54840504],\n",
       "        [-0.17666518, -1.45112571, -0.09599357],\n",
       "        [-0.29475164, -0.78043313,  0.12661668],\n",
       "        [-0.54041845, -0.33042951,  0.20247945],\n",
       "        [-1.98980245,  0.433177  ,  0.38177715],\n",
       "        [ 0.1767789 ,  0.79601951,  0.47125332],\n",
       "        [ 1.68796702,  1.1188719 ,  0.69625015],\n",
       "        [ 0.79626166,  1.34791325,  0.76602186]]),\n",
       " array([[-0.4596192 ,  0.0325884 ,  0.07862232, ..., -0.11290557,\n",
       "          0.07535215,  0.14999871],\n",
       "        [-0.18049463,  0.08229686,  0.39686155, ...,  0.1871813 ,\n",
       "          0.09705205,  0.11121284],\n",
       "        [-0.03693514,  0.0363833 ,  0.30388842, ...,  0.2086759 ,\n",
       "          0.10712735,  0.08134899]]),\n",
       " np.float64(843.5024751330668))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_interactive_effects(y, x, G, GF, gife_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75eb1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.72635102e+00,  2.28124935e+00,  1.22812353e+00],\n",
       "        [ 4.02710833e-02,  1.51142333e-01,  1.90706778e-03],\n",
       "        [-1.66325423e-04, -2.46372008e-04, -9.62130687e-05],\n",
       "        [ 8.83958512e-02,  4.86018278e-02,  1.51350747e-01],\n",
       "        [ 7.67235026e-02,  2.50690201e-02,  9.79905903e-02],\n",
       "        [-2.30373350e-04, -1.30037318e-02,  1.87113284e-03]]),\n",
       " array([2, 0, 1, 0, 1, 0, 1, 2, 0, 2, 2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 0, 2, 1, 0, 1, 1, 2, 1, 0, 0, 0, 1, 0, 2, 2, 0, 0,\n",
       "        1, 0, 2, 1, 2, 1, 0, 2, 1, 2, 1, 2, 0, 1, 1, 2, 2, 1, 2, 1, 0, 0,\n",
       "        2, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 0, 0, 1, 1, 2, 2, 0, 2, 0, 2, 2,\n",
       "        0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 2, 0, 1, 2, 0, 2, 0, 2,\n",
       "        0, 0, 0, 2, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 2,\n",
       "        2, 2, 1, 1, 0, 0, 0, 2, 2, 0, 1, 2, 0, 0, 2, 1, 0, 2, 1, 2, 1, 2,\n",
       "        2, 2, 0, 0, 1, 2, 0, 0, 0, 1, 1, 1, 2, 0, 2, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 2, 2, 0, 1, 0, 1, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 0,\n",
       "        0, 0, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 1, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0, 1, 0, 2, 0,\n",
       "        1, 1, 2, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 1, 0, 2, 0, 1, 2, 0, 2, 2,\n",
       "        0, 0, 2, 1, 1, 0, 2, 2, 1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 2, 2, 2, 1,\n",
       "        2, 1, 0, 0, 2, 2, 2, 0, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 2, 0, 0,\n",
       "        0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 0, 2, 1, 0,\n",
       "        1, 2, 1, 0, 0, 2, 0, 0, 1, 2, 1, 1, 0, 0, 2, 2, 2, 2, 0, 2, 1, 2,\n",
       "        1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 1, 0, 2, 1, 2, 2, 2, 0,\n",
       "        0, 2, 1, 2, 0, 1, 0, 0, 0, 1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0,\n",
       "        2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 1, 0, 2, 2, 2, 1, 1,\n",
       "        1, 0, 1, 1, 2, 0, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        1, 2, 2, 0, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1,\n",
       "        1, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 1, 2, 0, 0, 2, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 1, 1, 2, 2, 1, 1, 0, 2, 0, 1, 0, 0, 2, 0, 0,\n",
       "        2, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 2, 1, 2]),\n",
       " array([[-2.54148269, -1.44927154, -0.85467389],\n",
       "        [-0.18387067, -0.95137458, -1.81771178],\n",
       "        [ 0.0409958 , -0.64358871, -0.57894125],\n",
       "        [ 0.36748662, -0.53755329, -0.31279664],\n",
       "        [ 0.47462275,  0.17528235,  0.54015015],\n",
       "        [ 0.55027503,  0.65938506,  0.98660957],\n",
       "        [ 0.58408529,  1.21157303,  1.32840386],\n",
       "        [ 0.70788788,  1.53554769,  0.70895999]]),\n",
       " array([[-0.09802692, -0.06561766,  0.20670463, ...,  0.12802536,\n",
       "          0.03879114,  0.05071486],\n",
       "        [-0.30940371,  0.1292028 ,  0.45873716, ...,  0.31909437,\n",
       "          0.11318014,  0.38279741],\n",
       "        [-0.3585725 , -0.0398964 ,  0.21689893, ...,  0.07832782,\n",
       "          0.00290442,  0.02936944]]),\n",
       " np.float64(425.7710224114255))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_factors_initial(y, GF, T):\n",
    "    y_squeezed = np.squeeze(y).T\n",
    "    pca = PCA(n_components=GF.sum())\n",
    "    U = pca.fit_transform(y_squeezed) / pca.singular_values_\n",
    "    F = np.sqrt(T) * U\n",
    "    Lambda = F.T @ y_squeezed / T\n",
    "\n",
    "    return F, Lambda\n",
    "\n",
    "\n",
    "def _get_factors_hetrogeneous(y, x, beta, g, G, GF, T, N):\n",
    "    # NOTE this is not neeeded I believe\n",
    "    F = np.zeros((T, GF.sum()))\n",
    "    Lambda = np.zeros((GF.sum(), y.shape[0]))\n",
    "\n",
    "    for i in range(G):\n",
    "        y_squeezed_partial = np.atleast_2d(np.squeeze(y[g == i] - x[g == i] @ beta[:, i:i+1]).T)\n",
    "\n",
    "        pca = PCA(n_components=GF[i])\n",
    "        U = pca.fit_transform(y_squeezed_partial) / pca.singular_values_\n",
    "\n",
    "        F_partial = np.sqrt(T) * U\n",
    "        F[:, GF[:i].sum() : GF[: i + 1].sum()] = F_partial\n",
    "\n",
    "        # NOTE that here the correct beta is used\n",
    "        y_squeezed = np.squeeze(y - x @ beta[:, i:i+1]).T\n",
    "        Lambda_partial = F_partial.T @ y_squeezed / T\n",
    "        Lambda[GF[:i].sum() : GF[: i + 1].sum(), :] = Lambda_partial\n",
    "\n",
    "    return F, Lambda\n",
    "\n",
    "\n",
    "def _get_clusters_initial(Lambda, G, GF):\n",
    "    # FIXME this code is very bad, but it works\n",
    "    while True:\n",
    "        km = KMeans(n_clusters=G)\n",
    "        g = km.fit_predict(Lambda.T)\n",
    "\n",
    "        counts = np.bincount(g, minlength=G)\n",
    "        if np.all(counts >= (GF + 1)):\n",
    "            break\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "def _get_cluster_id(G, GF):\n",
    "    cluster_id = np.zeros(GF.sum(), dtype=np.int8)\n",
    "    for i in range(G):\n",
    "        cluster_id[GF[:i].sum() : GF[: i + 1].sum()] = i\n",
    "    return cluster_id\n",
    "\n",
    "\n",
    "# FIXME this code should be modified s.t. cannot return groups less than size\n",
    "# GF[i]\n",
    "def _get_clusters_hetrogeneous(y, x, beta, Lambda, g, G, F, GF, N, T):\n",
    "    res = np.zeros((N, T, G))\n",
    "    for i in range(G):\n",
    "        # TODO check if this is correct\n",
    "        # But I think so\n",
    "        res[:, :, i] = (\n",
    "            y.reshape(N, -1)\n",
    "            - x @ beta[:, i]\n",
    "            - (F[:, GF[:i].sum() : GF[: i + 1].sum()] @ Lambda[GF[:i].sum() : GF[: i + 1].sum(), :]).T\n",
    "        )\n",
    "    res_per_grouping = (res**2).sum(axis=1)\n",
    "    g = res_per_grouping.argmin(axis=1)\n",
    "\n",
    "    # Count size of each group\n",
    "    counts = np.bincount(g, minlength=G)\n",
    "\n",
    "    # Ensure minimum group sizes (GF[i] + 1)\n",
    "    min_sizes = GF + 1\n",
    "\n",
    "    # Check if any group is below minimum size\n",
    "    while np.any(counts < min_sizes):\n",
    "        # Find the most deficient group\n",
    "        target_group = np.argmin(counts - min_sizes)\n",
    "        needed = min_sizes[target_group] - counts[target_group]\n",
    "\n",
    "        if needed <= 0:\n",
    "            continue  # This group already meets its minimum\n",
    "\n",
    "        # Find elements not in this group\n",
    "        non_target_indices = np.where(g != target_group)[0]\n",
    "\n",
    "        # Sort by distance to target group\n",
    "        distances = res_per_grouping[non_target_indices, target_group]\n",
    "        closest_indices = non_target_indices[np.argsort(distances)]\n",
    "\n",
    "        # Try to reassign closest elements\n",
    "        reassigned = 0\n",
    "        for idx in closest_indices:\n",
    "            source_group = g[idx]\n",
    "\n",
    "            # Only reassign if source group has enough elements to spare\n",
    "            if counts[source_group] > min_sizes[source_group]:\n",
    "                g[idx] = target_group\n",
    "                counts[source_group] -= 1\n",
    "                counts[target_group] += 1\n",
    "                reassigned += 1\n",
    "\n",
    "                if reassigned >= needed:\n",
    "                    break\n",
    "\n",
    "        # If we couldn't reassign any elements, we're stuck\n",
    "        if reassigned == 0:\n",
    "            raise Exception(\"Cannot satisfy minimum group size constraints.\")\n",
    "\n",
    "    objective_value = res_per_grouping[np.arange(N), g].sum()\n",
    "\n",
    "    return g, objective_value\n",
    "\n",
    "\n",
    "# NOTE this ignores the factor structure\n",
    "def _estimate_beta_initial_hetrogeneous(y, x, g, K, G):\n",
    "    beta = np.zeros((K, G))\n",
    "    for i in range(G):\n",
    "        y_partial = y[g == i]\n",
    "        x_partial = x[g == i]\n",
    "\n",
    "        beta[:, i] = np.squeeze(lstsq(x_partial.reshape(-1, K), y_partial.reshape(-1, 1), rcond=None)[0])\n",
    "    return beta\n",
    "\n",
    "\n",
    "def _estimate_beta_hetrogeneous(y, x, g, GF, F, Lambda, K, N, T, G, kappa, gamma):\n",
    "    # TODO check if this is correct\n",
    "    # FIXME no it is not, i is undefined and this formula does not work here\n",
    "    beta = np.zeros((K, G))\n",
    "    res = np.zeros((N, T, G))\n",
    "    for i in range(G):\n",
    "        # TODO check if this is correct\n",
    "        # But I think so\n",
    "        res[:, :, i] = (\n",
    "            y.reshape(N, -1) - (F[:, GF[:i].sum() : GF[: i + 1].sum()] @ Lambda[GF[:i].sum() : GF[: i + 1].sum(), :]).T\n",
    "        )\n",
    "\n",
    "    y_star = res[np.arange(N), :, g]\n",
    "    # FIXME the np.arange could be cached or something\n",
    "    if kappa == 0:\n",
    "        for i in range(G):\n",
    "            beta[:, i] = np.squeeze(lstsq(x[g==i].reshape(-1, K), y_star[g==i].reshape(-1, 1), rcond=None)[0])\n",
    "        return beta\n",
    "\n",
    "    for i in range(G):\n",
    "        beta[:, i] = (GeneralizedLinearEstimator(penalty=SCAD(alpha=kappa, gamma=gamma))\n",
    "            .fit(x[g==i].reshape(-1, K), np.squeeze(y_star[g==i].reshape(-1, 1)))\n",
    "            .coef_)\n",
    "\n",
    "    return beta\n",
    "\n",
    "    # TODO check if this is correct\n",
    "    # But I think so\n",
    "    # beta = GeneralizedLinearEstimator(penalty=SCAD()).fit(x.reshape(-1, K), y_star.reshape(-1, 1))\n",
    "    # return beta\n",
    "\n",
    "\n",
    "# def _get_initial_values(y, x, G, GF, N, T, K, kappa, gamma):\n",
    "#     F, Lambda = _get_factors(y, GF, N)\n",
    "#     g = _get_clusters(Lambda, G)\n",
    "\n",
    "\n",
    "# NOTE implementing some sort of VNS could be quite beneficial, as it would\n",
    "# improve the performance of the algorithm quite a bit, though some modifications\n",
    "# would be needed\n",
    "def _grouped_interactive_effects_iteration_hetrogeneous(y, x, G, GF, N, T, K, kappa, gamma, tol, max_iterations):\n",
    "    last_objective_value = np.inf\n",
    "    F, Lambda = _get_factors_initial(y, GF, T)\n",
    "    g = _get_clusters_initial(Lambda, G, GF)\n",
    "    beta = _estimate_beta_initial_hetrogeneous(y, x, g, K, G)\n",
    "    F, Lambda = _get_factors_hetrogeneous(y, x, beta, g, G, GF, T, K)\n",
    "\n",
    "    obj_val_store = 5\n",
    "    objective_values = np.zeros(obj_val_store)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        g, objective_value = _get_clusters_hetrogeneous(y, x, beta, Lambda, g, G, F, GF, N, T)\n",
    "        F, Lambda = _get_factors_hetrogeneous(y, x, beta, g, G, GF, T, K)\n",
    "        beta = _estimate_beta_hetrogeneous(y, x, g, GF, F, Lambda, K, N, T, G, kappa, gamma)\n",
    "\n",
    "        objective_values[i % obj_val_store] = objective_value\n",
    "        if objective_values.max() - objective_values.min() < tol:\n",
    "            break\n",
    "\n",
    "        last_objective_value = objective_value\n",
    "\n",
    "    return beta, g, F, Lambda, last_objective_value\n",
    "\n",
    "\n",
    "def grouped_interactive_effects_hetrogeneous(y, x, G, GF = None, kappa=0.0, gamma=3.7, tol=1e-6, gife_iterations=100, max_iterations=1000):\n",
    "    \"\"\"Runs GIFE regression\"\"\"\n",
    "    N, T, K = x.shape\n",
    "    if GF is None:\n",
    "        GF = np.array([1] * G)\n",
    "    else:\n",
    "        GF = np.array(GF)  # Ensures that is an np array\n",
    "\n",
    "    best_objective_value = np.inf\n",
    "    best_g = None\n",
    "    best_beta = None\n",
    "    best_F = None\n",
    "    best_Lambda = None\n",
    "\n",
    "    # FIXME Lamda returns all possible factors and not only the ones that are used\n",
    "\n",
    "    for i in range(gife_iterations):\n",
    "        beta, g, F, Lambda, objective_value = _grouped_interactive_effects_iteration_hetrogeneous(\n",
    "            y, x, G, GF, N, T, K, kappa, gamma, tol, max_iterations\n",
    "        )\n",
    "\n",
    "        if objective_value < best_objective_value:\n",
    "            best_objective_value = objective_value\n",
    "            best_g = g\n",
    "            best_beta = beta\n",
    "            best_F = F\n",
    "            best_Lambda = Lambda\n",
    "\n",
    "    return best_beta, best_g, best_F, best_Lambda, best_objective_value\n",
    "\n",
    "\n",
    "grouped_interactive_effects_hetrogeneous(y, x, G, GF, gife_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1209b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.65229455e+00,  2.12116165e+00,  1.34512627e+00],\n",
       "        [ 1.68591497e-02, -3.10681780e-02, -2.77325371e-02],\n",
       "        [-2.22242090e-04, -1.69428013e-04, -6.66705575e-05],\n",
       "        [ 6.77848213e-02,  1.30026599e-01,  2.17672137e-01],\n",
       "        [ 3.74161885e-02,  9.57942175e-02,  8.89875454e-02],\n",
       "        [-3.82488607e-03,  6.07831171e-04,  1.47781709e-03]]),\n",
       " array([2, 1, 0, 1, 0, 1, 0, 2, 1, 2, 2, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1,\n",
       "        0, 0, 2, 1, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 1, 1, 0, 1, 2, 2, 1, 1,\n",
       "        0, 1, 2, 0, 2, 0, 1, 2, 0, 2, 0, 2, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1,\n",
       "        2, 1, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 2, 1, 2, 2,\n",
       "        1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 2, 0, 2, 1, 2, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1, 0, 2, 2, 0, 2, 1, 1, 1, 0, 2,\n",
       "        2, 2, 0, 0, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 2, 0, 1, 2, 0, 2, 0, 2,\n",
       "        2, 2, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0, 2, 1, 2, 2, 1, 1, 0, 0, 1, 0,\n",
       "        1, 2, 2, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "        1, 1, 0, 2, 2, 1, 1, 0, 1, 1, 0, 1, 2, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 1, 2, 1, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1, 0, 1, 2, 1,\n",
       "        1, 0, 2, 1, 1, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 1, 2, 2,\n",
       "        2, 1, 2, 0, 1, 1, 2, 2, 0, 0, 1, 1, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0,\n",
       "        2, 0, 1, 1, 2, 2, 2, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 0, 2, 0, 1, 1, 0, 2, 1, 1,\n",
       "        1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 0, 2, 2, 2, 1, 1, 1, 1, 1, 2, 0, 1,\n",
       "        0, 2, 0, 1, 1, 2, 1, 1, 0, 1, 0, 0, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1,\n",
       "        0, 1, 1, 1, 2, 1, 1, 0, 2, 1, 0, 1, 0, 1, 0, 1, 2, 0, 0, 1, 1, 1,\n",
       "        1, 1, 0, 2, 0, 0, 1, 1, 1, 0, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2,\n",
       "        2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 0, 1, 2, 2, 2, 0, 0,\n",
       "        0, 1, 1, 0, 2, 1, 2, 1, 0, 2, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "        0, 2, 2, 1, 0, 2, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1, 2, 0, 2, 2, 0, 1,\n",
       "        0, 1, 0, 1, 2, 1, 1, 2, 1, 1, 2, 1, 0, 1, 1, 2, 0, 2, 1, 1, 2, 2,\n",
       "        1, 2, 2, 2, 2, 1, 1, 0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 1, 1,\n",
       "        2, 2, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 2, 0, 2]),\n",
       " array([[-1.77835511, -2.16165652,  1.50200022, -0.97431316,  1.05081992],\n",
       "        [-0.90440222, -0.69132261, -1.79305913, -1.3913728 ,  0.45814564],\n",
       "        [-0.57022612, -0.28145021, -0.7164712 , -0.89518891, -0.28584622],\n",
       "        [-0.22857561,  0.00830202, -0.84781252, -0.29797481,  0.00775691],\n",
       "        [ 0.29211775,  0.44205866, -0.02872154,  0.07458042, -2.4199105 ],\n",
       "        [ 0.74610092,  0.59860972,  0.38433977,  0.87519708, -0.02065586],\n",
       "        [ 1.13463699,  0.89831328,  0.64103061,  1.46182953,  0.6944086 ],\n",
       "        [ 1.30870341,  1.18714566,  0.8586938 ,  1.14724265,  0.51528151]]),\n",
       " array([[-0.16461793,  0.10897361,  0.44096202, ...,  0.30468742,\n",
       "          0.17809937,  0.30947322],\n",
       "        [-0.06960674,  0.06339114,  0.38510637, ...,  0.24254668,\n",
       "          0.15227261,  0.16642952],\n",
       "        [-0.21730687,  0.04986523,  0.13107891, ..., -0.01219209,\n",
       "          0.00166647,  0.05242022],\n",
       "        [-0.31057738,  0.04130451,  0.32793085, ...,  0.10885879,\n",
       "          0.07688388,  0.11493786],\n",
       "        [-0.23879935,  0.00851721, -0.06745311, ..., -0.22586916,\n",
       "          0.02237417,  0.11650291]]),\n",
       " np.float64(345.6176985409686))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_interactive_effects_hetrogeneous(y, x, G, GF, gife_iterations=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
