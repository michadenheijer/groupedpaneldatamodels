{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ca1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy.linalg import lstsq\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda0bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251dc13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>exper</th>\n",
       "      <th>hours</th>\n",
       "      <th>married</th>\n",
       "      <th>union</th>\n",
       "      <th>expersq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nr</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">13</th>\n",
       "      <th>1980</th>\n",
       "      <td>1</td>\n",
       "      <td>2672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>2</td>\n",
       "      <td>2320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>3</td>\n",
       "      <td>2940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>4</td>\n",
       "      <td>2960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>5</td>\n",
       "      <td>3071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">12548</th>\n",
       "      <th>1983</th>\n",
       "      <td>8</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>9</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>10</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>11</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>12</td>\n",
       "      <td>3380</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4360 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            exper  hours  married  union  expersq\n",
       "nr    year                                       \n",
       "13    1980      1   2672        0      0        1\n",
       "      1981      2   2320        0      1        4\n",
       "      1982      3   2940        0      0        9\n",
       "      1983      4   2960        0      0       16\n",
       "      1984      5   3071        0      0       25\n",
       "...           ...    ...      ...    ...      ...\n",
       "12548 1983      8   2080        1      0       64\n",
       "      1984      9   2080        1      1       81\n",
       "      1985     10   2080        1      0      100\n",
       "      1986     11   2080        1      1      121\n",
       "      1987     12   3380        1      1      144\n",
       "\n",
       "[4360 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nr     year\n",
       "13     1980    1.197540\n",
       "       1981    1.853060\n",
       "       1982    1.344462\n",
       "       1983    1.433213\n",
       "       1984    1.568125\n",
       "                 ...   \n",
       "12548  1983    1.591879\n",
       "       1984    1.212543\n",
       "       1985    1.765962\n",
       "       1986    1.745894\n",
       "       1987    1.466543\n",
       "Name: lwage, Length: 4360, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from linearmodels.datasets import wage_panel\n",
    "wage_panel_df = wage_panel.load()\n",
    "\n",
    "wage_panel_df.set_index(['nr', 'year'], inplace=True)\n",
    "y = wage_panel_df['lwage']\n",
    "x = wage_panel_df.drop(columns=[\"occupation\", \"lwage\", \"black\", \"hisp\", \"educ\"])\n",
    "display(x)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d5e69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 8, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = x.index.get_level_values(0).nunique()\n",
    "T = x.index.get_level_values(1).nunique()\n",
    "K = x.shape[1]\n",
    "N, T, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c3df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[   1, 2672,    0,    0,    1],\n",
       "         [   2, 2320,    0,    1,    4],\n",
       "         [   3, 2940,    0,    0,    9],\n",
       "         ...,\n",
       "         [   6, 2864,    0,    0,   36],\n",
       "         [   7, 2994,    0,    0,   49],\n",
       "         [   8, 2640,    0,    0,   64]],\n",
       " \n",
       "        [[   4, 2484,    0,    0,   16],\n",
       "         [   5, 2804,    0,    0,   25],\n",
       "         [   6, 2530,    0,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2164,    0,    0,   81],\n",
       "         [  10, 2749,    0,    0,  100],\n",
       "         [  11, 2476,    0,    0,  121]],\n",
       " \n",
       "        [[   4, 2332,    1,    0,   16],\n",
       "         [   5, 2116,    1,    0,   25],\n",
       "         [   6, 2500,    1,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2340,    1,    0,   81],\n",
       "         [  10, 2340,    1,    0,  100],\n",
       "         [  11, 2340,    1,    0,  121]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   4, 2008,    1,    0,   16],\n",
       "         [   5, 3190,    0,    0,   25],\n",
       "         [   6, 2584,    0,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2290,    1,    0,   81],\n",
       "         [  10, 3151,    1,    0,  100],\n",
       "         [  11, 3276,    1,    0,  121]],\n",
       " \n",
       "        [[   2, 2080,    0,    0,    4],\n",
       "         [   3, 2000,    0,    0,    9],\n",
       "         [   4, 1800,    1,    0,   16],\n",
       "         ...,\n",
       "         [   7, 2080,    1,    0,   49],\n",
       "         [   8, 2080,    1,    0,   64],\n",
       "         [   9, 2080,    1,    0,   81]],\n",
       " \n",
       "        [[   5, 2000,    0,    0,   25],\n",
       "         [   6, 2112,    0,    0,   36],\n",
       "         [   7, 2080,    0,    0,   49],\n",
       "         ...,\n",
       "         [  10, 2080,    1,    0,  100],\n",
       "         [  11, 2080,    1,    1,  121],\n",
       "         [  12, 3380,    1,    1,  144]]]),\n",
       " array([[[ 1.19754  ],\n",
       "         [ 1.85306  ],\n",
       "         [ 1.344462 ],\n",
       "         ...,\n",
       "         [ 1.699891 ],\n",
       "         [-0.7202626],\n",
       "         [ 1.669188 ]],\n",
       " \n",
       "        [[ 1.675962 ],\n",
       "         [ 1.518398 ],\n",
       "         [ 1.559191 ],\n",
       "         ...,\n",
       "         [ 1.608588 ],\n",
       "         [ 1.572385 ],\n",
       "         [ 1.820334 ]],\n",
       " \n",
       "        [[ 1.515963 ],\n",
       "         [ 1.735379 ],\n",
       "         [ 1.631744 ],\n",
       "         ...,\n",
       "         [ 2.266662 ],\n",
       "         [ 2.069944 ],\n",
       "         [ 2.873161 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.9724026],\n",
       "         [ 1.324886 ],\n",
       "         [ 0.962707 ],\n",
       "         ...,\n",
       "         [ 2.037503 ],\n",
       "         [ 1.148221 ],\n",
       "         [ 1.30674  ]],\n",
       " \n",
       "        [[ 1.840042 ],\n",
       "         [ 2.174752 ],\n",
       "         [ 2.122767 ],\n",
       "         ...,\n",
       "         [ 2.207794 ],\n",
       "         [ 2.381883 ],\n",
       "         [ 2.342917 ]],\n",
       " \n",
       "        [[ 1.130545 ],\n",
       "         [ 1.311603 ],\n",
       "         [ 0.8324816],\n",
       "         ...,\n",
       "         [ 1.765962 ],\n",
       "         [ 1.745894 ],\n",
       "         [ 1.466543 ]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.values.reshape(N, T, K)\n",
    "y = y.values.reshape(N, T, 1)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de35749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d150f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43308c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f5d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04d0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute theta\n",
    "# # theta, ssr, rank, singular = lstsq(x_stack, , rcond=None)\n",
    "# iterations = 10000\n",
    "# objective_value = np.inf\n",
    "# tolerance = 1e-8\n",
    "# G = 3\n",
    "\n",
    "# x_stack = x.reshape(-1, K)\n",
    "# y_stack = y.reshape(-1, 1)\n",
    "\n",
    "# num_start_vars = x.shape[1] + G\n",
    "# starting_vals = np.random.choice(N, num_start_vars, replace=False)\n",
    "# x_stack_start = x[starting_vals].reshape(-1, K)\n",
    "# y_stack_start = y[starting_vals].reshape(-1, 1)\n",
    "\n",
    "# # NOTE in the paper this should be done on just a subset of the data for initialization\n",
    "# theta, ssr, rank, singular = lstsq(x_stack_start, y_stack_start, rcond=None)\n",
    "# residuals = y_stack - x_stack @ theta\n",
    "# # residuals.reshape(N, T)\n",
    "# theta\n",
    "\n",
    "# random_draws = np.random.choice(N, size=G, replace=False)\n",
    "# alpha = np.squeeze(y[random_draws] - x[random_draws, :, :] @ theta)\n",
    "# alpha\n",
    "\n",
    "# res = np.squeeze(y - x @ theta)\n",
    "# euclidean_distance_between_grouping = ((res[None, :, :] - alpha[:, None, :]) ** 2).sum(axis=2)\n",
    "# # FIXME some code should check if all values are included, and should create a new grouping if not\n",
    "# g = np.argmin(euclidean_distance_between_grouping, axis=0)  # Closest group\n",
    "# g\n",
    "\n",
    "# res = np.squeeze(y - x @ theta)\n",
    "\n",
    "# counts = np.bincount(g)[:, None]  # (G, 1) — number of elements in each group\n",
    "# sums = np.zeros((G, res.shape[1]))  # (G, K) — sum of residuals per group\n",
    "# np.add.at(sums, g, res)  # sums[i] += res[j] for all j where g[j] == i\n",
    "# alpha = sums / counts  # mean = sum / count\n",
    "# alpha\n",
    "\n",
    "# obj_val_array = np.zeros(iterations)\n",
    "\n",
    "# for i in range(iterations):\n",
    "#     # Compute alpha\n",
    "#     counts = np.bincount(g)[:, None]  # (G, 1) — number of elements in each group\n",
    "#     sums = np.zeros((G, res.shape[1]))  # (G, K) — sum of residuals per group\n",
    "#     np.add.at(sums, g, res)  # sums[i] += res[j] for all j where g[j] == i\n",
    "#     alpha = sums / counts  # mean = sum / count\n",
    "\n",
    "#     # Compute theta\n",
    "#     theta, ssr, rank, singular = lstsq(x_stack, y_stack - alpha[g].reshape(-1, 1), rcond=None) # TODO check if this makes sense\n",
    "\n",
    "#     # Compute groupings\n",
    "#     res = np.squeeze(y - x @ theta)\n",
    "#     euclidean_distance_between_grouping = ((res[None, :, :] - alpha[:, None, :]) ** 2).sum(axis=2)\n",
    "#     # FIXME some code should check if all values are included, and should create a new grouping if not\n",
    "#     g = np.argmin(euclidean_distance_between_grouping, axis=0)  # Closest group\n",
    "\n",
    "#     # Check for convergence\n",
    "#     new_objective_value = ((res - alpha[g])**2).sum()\n",
    "#     if abs(objective_value - new_objective_value) < tolerance:\n",
    "#         break\n",
    "#     objective_value = new_objective_value\n",
    "\n",
    "#     obj_val_array[i] = objective_value\n",
    "\n",
    "# display(i)\n",
    "# display(objective_value)\n",
    "# display(g)\n",
    "# display(alpha)\n",
    "# display(theta)\n",
    "# # Recompute alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98572ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.27308016,  0.14713952,  0.18722496,  0.12929793,  0.18195473,\n",
       "          0.16824806,  0.23583886,  0.2233761 ],\n",
       "        [-0.20940534, -0.32104309, -0.16929891, -0.045043  ,  0.11026162,\n",
       "          0.16522911,  0.23434463,  0.23495499],\n",
       "        [ 0.13984353,  0.12236095,  0.03127673, -0.0252122 , -0.06879357,\n",
       "         -0.08669119, -0.08572159, -0.02706265]]),\n",
       " array([2, 2, 1, 2, 2, 0, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 0, 1, 2,\n",
       "        2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2,\n",
       "        2, 1, 2, 2, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 1, 2,\n",
       "        1, 2, 2, 1, 2, 2, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "        2, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2,\n",
       "        2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2,\n",
       "        1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "        2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 1, 1,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "        2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1,\n",
       "        2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
       "        2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 1, 1, 1, 0, 2, 2, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1,\n",
       "        2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "        1, 2, 2, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
       "        2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 0, 2, 1, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 1, 1, 0, 1, 1, 2, 2, 2, 1, 1, 1, 0, 2, 2, 2, 1, 1, 2, 1,\n",
       "        2, 2, 2, 2, 1, 2, 2, 2, 0, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1,\n",
       "        1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2,\n",
       "        1, 1, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 2, 0,\n",
       "        1, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @njit\n",
    "def _get_starting_values(y, x, G: int, N: int, K: int):\n",
    "    \"\"\"Generates the starting values of theta\"\"\"\n",
    "    num_start_vars: int = x.shape[1] + G # FIXME I believe that shape is slow in Cython\n",
    "    random_draws_theta = np.random.choice(N, num_start_vars, replace=False)\n",
    "    x_stack_start = x[random_draws_theta].reshape(-1, K)\n",
    "    y_stack_start = y[random_draws_theta].reshape(-1, 1)\n",
    "\n",
    "    # FIXME some errors may arise, maybe add some checks\n",
    "    theta_init = lstsq(x_stack_start, y_stack_start, rcond=None)[0]\n",
    "\n",
    "    random_draws_alpha = np.random.choice(N, size=G, replace=False)\n",
    "    alpha_init = np.squeeze(y[random_draws_alpha] - x[random_draws_alpha, :, :] @ theta_init)\n",
    "\n",
    "    return theta_init, alpha_init\n",
    "\n",
    "@njit\n",
    "def _compute_groupings(res, alpha):\n",
    "    \"\"\"Computes the groupings based on the residuals and alpha\"\"\"\n",
    "    euclidean_distance_between_grouping = ((res[None, :, :] - alpha[:, None, :]) ** 2).sum(axis=2)\n",
    "    g = np.argmin(euclidean_distance_between_grouping, axis=0)  # Closest group\n",
    "    return g\n",
    "\n",
    "# @njit\n",
    "def _compute_alpha(res, g, G):\n",
    "    \"\"\"Computes the alpha values based on the residuals and groupings\"\"\"\n",
    "    counts = np.bincount(g, minlength=G)[:, None]  # (G, 1) — number of elements in each group\n",
    "    sums = np.zeros((G, res.shape[1]))  # (G, K) — sum of residuals per group\n",
    "    np.add.at(sums, g, res)  # sums[i] += res[j] for all j where g[j] == i\n",
    "    alpha = sums / counts  # mean = sum / count\n",
    "    return alpha\n",
    "\n",
    "# @njit\n",
    "def _compute_theta(x, y, alpha, g):\n",
    "    \"\"\"Computes the theta values based on the x, y, alpha and groupings\"\"\"\n",
    "    # FIXME check if this makes sense\n",
    "    K = x.shape[2] # FIXME I believe that shape is slow in Cython\n",
    "    theta = lstsq(x.reshape(-1, K), y.reshape(-1, 1) - alpha[g].reshape(-1, 1), rcond=None)[0]\n",
    "    return theta\n",
    "\n",
    "# @njit\n",
    "def _compute_residuals(y, x, theta):\n",
    "    \"\"\"Computes the residuals based on y, x and theta\"\"\"\n",
    "    res = np.squeeze(y - x @ theta)\n",
    "    return res\n",
    "\n",
    "@njit\n",
    "def _compute_objective_value(res, alpha, g):\n",
    "    \"\"\"Computes the objective value based on the residuals, alpha and groupings\"\"\"\n",
    "    objective_value = ((res - alpha[g])**2).sum()\n",
    "    return objective_value\n",
    "\n",
    "def _reorder_groups(g, alpha):\n",
    "    \"\"\"Reorders the groups based on the first value of alpha\"\"\"\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    mapping = np.argsort(alpha[:, 0])\n",
    "    ordered_g = np.argsort(mapping)[g]\n",
    "    ordered_alpha = alpha[mapping]\n",
    "    return ordered_g, ordered_alpha\n",
    "\n",
    "\n",
    "def _grouped_fixed_effects_iteration(y, x, G: int, N: int, K: int, max_iter = 10000, tol=1e-8):\n",
    "    # FIXME possibly create some sort of array that stores these values\n",
    "    # Could be used for debugging\n",
    "    theta, alpha = _get_starting_values(y, x, G, N, K)\n",
    "    res = _compute_residuals(y, x, theta)\n",
    "    g = _compute_groupings(res, alpha)\n",
    "\n",
    "    objective_value = np.inf\n",
    "\n",
    "    iterations_used = 0\n",
    "    for i in range(max_iter):\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        theta = _compute_theta(x, y, alpha, g)\n",
    "        res = _compute_residuals(y, x, theta)\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        g = _compute_groupings(res, alpha)\n",
    "        new_objective_value = _compute_objective_value(res, alpha, g)\n",
    "\n",
    "        if abs(objective_value - new_objective_value) < tol:\n",
    "            iterations_used = i\n",
    "            objective_value = new_objective_value\n",
    "            break\n",
    "\n",
    "        objective_value = new_objective_value\n",
    "\n",
    "    return theta, alpha, g, iterations_used, objective_value\n",
    "\n",
    "def _compute_eta(y_bar, x_bar, theta):\n",
    "    \"\"\"Computes the eta values based on y_bar, x_bar and theta\"\"\"\n",
    "    eta = np.squeeze(y_bar - x_bar @ theta)\n",
    "    return eta\n",
    "\n",
    "# FIXME not used right now but still neccesary\n",
    "def _compute_statistics(objective_value, N, T, K, G):\n",
    "    \"\"\"Computes the statistics based on the objective value, N, T, K and G\"\"\"\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    sigma_squared = 1 / (N * T - G * T - N - K) * objective_value\n",
    "    BIC = 1/(N*T) * objective_value + sigma_squared * (G * T + N + K) / (N * T)\n",
    "    return sigma_squared, BIC\n",
    "\n",
    "\n",
    "def grouped_fixed_effects(y, x, G, max_iter=10000, tol=1e-8, gfe_iterations=20, unit_specific_effects=False):\n",
    "    \"\"\"\n",
    "    Computes the grouped fixed effects using the algorithm described in the paper.\n",
    "    \"\"\"\n",
    "    # FIXME not really required if unit_specific_effects is False\n",
    "    # But this seems like the easiest implementation\n",
    "    x_bar = np.mean(x, axis=1, keepdims=True)\n",
    "    y_bar = np.mean(y, axis=1, keepdims=True)\n",
    "\n",
    "    best_theta = None\n",
    "    best_alpha = None\n",
    "    best_g = None\n",
    "    best_iterations_used = None\n",
    "    best_objective_value = np.inf\n",
    "\n",
    "    N = x.shape[0]\n",
    "    K = x.shape[2]\n",
    "\n",
    "    # FIXME this code does not drop constant binary variables by itself\n",
    "    # The input class should be able to do this\n",
    "    if unit_specific_effects:\n",
    "        # Demean x and y\n",
    "        x = x - x_bar\n",
    "        y = y - y_bar\n",
    "\n",
    "    for _ in range(gfe_iterations):\n",
    "        theta, alpha, g, iterations_used, objective_value = _grouped_fixed_effects_iteration(\n",
    "            y,\n",
    "            x,\n",
    "            G,\n",
    "            N,\n",
    "            K,\n",
    "            max_iter,\n",
    "            tol\n",
    "        )\n",
    "\n",
    "        if objective_value < best_objective_value:\n",
    "            best_objective_value = objective_value\n",
    "            best_theta = theta\n",
    "            best_g, best_alpha = _reorder_groups(g, alpha)\n",
    "            # best_g, best_alpha = g, alpha\n",
    "            best_iterations_used = iterations_used\n",
    "\n",
    "    if unit_specific_effects:\n",
    "        eta = _compute_eta(y_bar, x_bar, best_theta)\n",
    "        return best_theta, best_alpha, best_g, eta, best_iterations_used, best_objective_value\n",
    "\n",
    "    # NOTE None is for lack of unit specific effects\n",
    "    return best_theta, best_alpha, best_g, None, best_iterations_used, best_objective_value\n",
    "\n",
    "grouped_fixed_effects(y, x, 3, max_iter=10000, tol=1e-8, gfe_iterations=100, unit_specific_effects=True)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0a76e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 5],\n",
       "       [0, 1, 2]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "test[[1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e609ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.500000e+00, 2.807625e+03, 0.000000e+00, 1.250000e-01,\n",
       "        2.550000e+01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(545, 1, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 4.56531735e-02],\n",
       "        [-8.76268692e-05],\n",
       "        [ 1.04546615e-01],\n",
       "        [ 6.09680537e-02],\n",
       "        [-5.46261795e-03]]),\n",
       " array([[1.49548037, 1.56936038, 1.61280633, 1.66662319, 1.78230364,\n",
       "         1.87430794, 1.98308263, 2.11751816],\n",
       "        [1.02439658, 1.10644043, 1.16106896, 1.23158154, 1.2985915 ,\n",
       "         1.36475815, 1.51461777, 1.65992997],\n",
       "        [1.81953868, 2.01490575, 2.10068919, 2.16790666, 2.26021116,\n",
       "         2.35212556, 2.41629442, 2.49623128]]),\n",
       " array([1, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0,\n",
       "        2, 2, 1, 0, 2, 0, 1, 2, 0, 2, 2, 1, 2, 0, 0, 0, 2, 0, 1, 1, 0, 0,\n",
       "        2, 0, 1, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 1,\n",
       "        1, 0, 1, 2, 2, 0, 2, 0, 0, 1, 2, 0, 0, 2, 2, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 1, 1, 2, 1, 0, 1, 0, 0,\n",
       "        0, 0, 2, 1, 0, 0, 0, 1, 2, 2, 0, 0, 2, 1, 1, 2, 1, 0, 0, 0, 2, 1,\n",
       "        1, 1, 2, 2, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0, 1, 2, 0, 1, 2, 1, 2, 1,\n",
       "        1, 0, 0, 0, 2, 1, 1, 0, 0, 2, 2, 2, 1, 0, 1, 0, 0, 0, 2, 2, 0, 2,\n",
       "        0, 1, 1, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 2, 0, 2, 2, 0, 2, 0,\n",
       "        2, 0, 0, 0, 2, 2, 2, 1, 0, 2, 2, 0, 0, 2, 0, 2, 1, 0, 2, 0, 1, 0,\n",
       "        2, 2, 1, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 2, 2, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 1, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 2,\n",
       "        1, 2, 0, 0, 1, 1, 1, 0, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0,\n",
       "        2, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 0, 0, 2, 0, 0, 1, 2, 0,\n",
       "        2, 1, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 1, 2, 0,\n",
       "        2, 0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 0, 2, 0, 2, 0, 1, 2, 2, 0, 2, 1,\n",
       "        0, 0, 2, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 2,\n",
       "        2, 0, 0, 2, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 2, 0, 2, 2, 0, 0, 2, 0,\n",
       "        2, 1, 1, 0, 2, 1, 2, 1, 2, 0, 2, 2, 2, 0, 0, 0, 1, 2, 1, 1, 2, 2,\n",
       "        2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 2, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 2, 1]),\n",
       " None,\n",
       " 836,\n",
       " 576.0328001778433)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_fixed_effects(y, x, 3, max_iter=10000, tol=1e-6, gfe_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1816187",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bonhomme_manresa'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbonhomme_manresa\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'bonhomme_manresa'"
     ]
    }
   ],
   "source": [
    "import bonhomme_manresa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
