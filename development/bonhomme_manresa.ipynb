{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ca1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy.linalg import lstsq\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda0bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251dc13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>exper</th>\n",
       "      <th>hours</th>\n",
       "      <th>married</th>\n",
       "      <th>union</th>\n",
       "      <th>expersq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nr</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">13</th>\n",
       "      <th>1980</th>\n",
       "      <td>1</td>\n",
       "      <td>2672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>2</td>\n",
       "      <td>2320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>3</td>\n",
       "      <td>2940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>4</td>\n",
       "      <td>2960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>5</td>\n",
       "      <td>3071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">12548</th>\n",
       "      <th>1983</th>\n",
       "      <td>8</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>9</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>10</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>11</td>\n",
       "      <td>2080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>12</td>\n",
       "      <td>3380</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4360 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            exper  hours  married  union  expersq\n",
       "nr    year                                       \n",
       "13    1980      1   2672        0      0        1\n",
       "      1981      2   2320        0      1        4\n",
       "      1982      3   2940        0      0        9\n",
       "      1983      4   2960        0      0       16\n",
       "      1984      5   3071        0      0       25\n",
       "...           ...    ...      ...    ...      ...\n",
       "12548 1983      8   2080        1      0       64\n",
       "      1984      9   2080        1      1       81\n",
       "      1985     10   2080        1      0      100\n",
       "      1986     11   2080        1      1      121\n",
       "      1987     12   3380        1      1      144\n",
       "\n",
       "[4360 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "nr     year\n",
       "13     1980    1.197540\n",
       "       1981    1.853060\n",
       "       1982    1.344462\n",
       "       1983    1.433213\n",
       "       1984    1.568125\n",
       "                 ...   \n",
       "12548  1983    1.591879\n",
       "       1984    1.212543\n",
       "       1985    1.765962\n",
       "       1986    1.745894\n",
       "       1987    1.466543\n",
       "Name: lwage, Length: 4360, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from linearmodels.datasets import wage_panel\n",
    "wage_panel_df = wage_panel.load()\n",
    "\n",
    "wage_panel_df.set_index(['nr', 'year'], inplace=True)\n",
    "y = wage_panel_df['lwage']\n",
    "x = wage_panel_df.drop(columns=[\"occupation\", \"lwage\", \"black\", \"hisp\", \"educ\"])\n",
    "display(x)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d5e69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 8, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = x.index.get_level_values(0).nunique()\n",
    "T = x.index.get_level_values(1).nunique()\n",
    "K = x.shape[1]\n",
    "N, T, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c3df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[   1, 2672,    0,    0,    1],\n",
       "         [   2, 2320,    0,    1,    4],\n",
       "         [   3, 2940,    0,    0,    9],\n",
       "         ...,\n",
       "         [   6, 2864,    0,    0,   36],\n",
       "         [   7, 2994,    0,    0,   49],\n",
       "         [   8, 2640,    0,    0,   64]],\n",
       " \n",
       "        [[   4, 2484,    0,    0,   16],\n",
       "         [   5, 2804,    0,    0,   25],\n",
       "         [   6, 2530,    0,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2164,    0,    0,   81],\n",
       "         [  10, 2749,    0,    0,  100],\n",
       "         [  11, 2476,    0,    0,  121]],\n",
       " \n",
       "        [[   4, 2332,    1,    0,   16],\n",
       "         [   5, 2116,    1,    0,   25],\n",
       "         [   6, 2500,    1,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2340,    1,    0,   81],\n",
       "         [  10, 2340,    1,    0,  100],\n",
       "         [  11, 2340,    1,    0,  121]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   4, 2008,    1,    0,   16],\n",
       "         [   5, 3190,    0,    0,   25],\n",
       "         [   6, 2584,    0,    0,   36],\n",
       "         ...,\n",
       "         [   9, 2290,    1,    0,   81],\n",
       "         [  10, 3151,    1,    0,  100],\n",
       "         [  11, 3276,    1,    0,  121]],\n",
       " \n",
       "        [[   2, 2080,    0,    0,    4],\n",
       "         [   3, 2000,    0,    0,    9],\n",
       "         [   4, 1800,    1,    0,   16],\n",
       "         ...,\n",
       "         [   7, 2080,    1,    0,   49],\n",
       "         [   8, 2080,    1,    0,   64],\n",
       "         [   9, 2080,    1,    0,   81]],\n",
       " \n",
       "        [[   5, 2000,    0,    0,   25],\n",
       "         [   6, 2112,    0,    0,   36],\n",
       "         [   7, 2080,    0,    0,   49],\n",
       "         ...,\n",
       "         [  10, 2080,    1,    0,  100],\n",
       "         [  11, 2080,    1,    1,  121],\n",
       "         [  12, 3380,    1,    1,  144]]]),\n",
       " array([[[ 1.19754  ],\n",
       "         [ 1.85306  ],\n",
       "         [ 1.344462 ],\n",
       "         ...,\n",
       "         [ 1.699891 ],\n",
       "         [-0.7202626],\n",
       "         [ 1.669188 ]],\n",
       " \n",
       "        [[ 1.675962 ],\n",
       "         [ 1.518398 ],\n",
       "         [ 1.559191 ],\n",
       "         ...,\n",
       "         [ 1.608588 ],\n",
       "         [ 1.572385 ],\n",
       "         [ 1.820334 ]],\n",
       " \n",
       "        [[ 1.515963 ],\n",
       "         [ 1.735379 ],\n",
       "         [ 1.631744 ],\n",
       "         ...,\n",
       "         [ 2.266662 ],\n",
       "         [ 2.069944 ],\n",
       "         [ 2.873161 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.9724026],\n",
       "         [ 1.324886 ],\n",
       "         [ 0.962707 ],\n",
       "         ...,\n",
       "         [ 2.037503 ],\n",
       "         [ 1.148221 ],\n",
       "         [ 1.30674  ]],\n",
       " \n",
       "        [[ 1.840042 ],\n",
       "         [ 2.174752 ],\n",
       "         [ 2.122767 ],\n",
       "         ...,\n",
       "         [ 2.207794 ],\n",
       "         [ 2.381883 ],\n",
       "         [ 2.342917 ]],\n",
       " \n",
       "        [[ 1.130545 ],\n",
       "         [ 1.311603 ],\n",
       "         [ 0.8324816],\n",
       "         ...,\n",
       "         [ 1.765962 ],\n",
       "         [ 1.745894 ],\n",
       "         [ 1.466543 ]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.values.reshape(N, T, K)\n",
    "y = y.values.reshape(N, T, 1)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de35749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d150f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43308c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f5d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04d0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute theta\n",
    "# # theta, ssr, rank, singular = lstsq(x_stack, , rcond=None)\n",
    "# iterations = 10000\n",
    "# objective_value = np.inf\n",
    "# tolerance = 1e-8\n",
    "# G = 3\n",
    "\n",
    "# x_stack = x.reshape(-1, K)\n",
    "# y_stack = y.reshape(-1, 1)\n",
    "\n",
    "# num_start_vars = x.shape[1] + G\n",
    "# starting_vals = np.random.choice(N, num_start_vars, replace=False)\n",
    "# x_stack_start = x[starting_vals].reshape(-1, K)\n",
    "# y_stack_start = y[starting_vals].reshape(-1, 1)\n",
    "\n",
    "# # NOTE in the paper this should be done on just a subset of the data for initialization\n",
    "# theta, ssr, rank, singular = lstsq(x_stack_start, y_stack_start, rcond=None)\n",
    "# residuals = y_stack - x_stack @ theta\n",
    "# # residuals.reshape(N, T)\n",
    "# theta\n",
    "\n",
    "# random_draws = np.random.choice(N, size=G, replace=False)\n",
    "# alpha = np.squeeze(y[random_draws] - x[random_draws, :, :] @ theta)\n",
    "# alpha\n",
    "\n",
    "# res = np.squeeze(y - x @ theta)\n",
    "# euclidean_distance_between_grouping = ((res[None, :, :] - alpha[:, None, :]) ** 2).sum(axis=2)\n",
    "# # FIXME some code should check if all values are included, and should create a new grouping if not\n",
    "# g = np.argmin(euclidean_distance_between_grouping, axis=0)  # Closest group\n",
    "# g\n",
    "\n",
    "# res = np.squeeze(y - x @ theta)\n",
    "\n",
    "# counts = np.bincount(g)[:, None]  # (G, 1) â€” number of elements in each group\n",
    "# sums = np.zeros((G, res.shape[1]))  # (G, K) â€” sum of residuals per group\n",
    "# np.add.at(sums, g, res)  # sums[i] += res[j] for all j where g[j] == i\n",
    "# alpha = sums / counts  # mean = sum / count\n",
    "# alpha\n",
    "\n",
    "# obj_val_array = np.zeros(iterations)\n",
    "\n",
    "# for i in range(iterations):\n",
    "#     # Compute alpha\n",
    "#     counts = np.bincount(g)[:, None]  # (G, 1) â€” number of elements in each group\n",
    "#     sums = np.zeros((G, res.shape[1]))  # (G, K) â€” sum of residuals per group\n",
    "#     np.add.at(sums, g, res)  # sums[i] += res[j] for all j where g[j] == i\n",
    "#     alpha = sums / counts  # mean = sum / count\n",
    "\n",
    "#     # Compute theta\n",
    "#     theta, ssr, rank, singular = lstsq(x_stack, y_stack - alpha[g].reshape(-1, 1), rcond=None) # TODO check if this makes sense\n",
    "\n",
    "#     # Compute groupings\n",
    "#     res = np.squeeze(y - x @ theta)\n",
    "#     euclidean_distance_between_grouping = ((res[None, :, :] - alpha[:, None, :]) ** 2).sum(axis=2)\n",
    "#     # FIXME some code should check if all values are included, and should create a new grouping if not\n",
    "#     g = np.argmin(euclidean_distance_between_grouping, axis=0)  # Closest group\n",
    "\n",
    "#     # Check for convergence\n",
    "#     new_objective_value = ((res - alpha[g])**2).sum()\n",
    "#     if abs(objective_value - new_objective_value) < tolerance:\n",
    "#         break\n",
    "#     objective_value = new_objective_value\n",
    "\n",
    "#     obj_val_array[i] = objective_value\n",
    "\n",
    "# display(i)\n",
    "# display(objective_value)\n",
    "# display(g)\n",
    "# display(alpha)\n",
    "# display(theta)\n",
    "# # Recompute alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98572ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.09575509e-01],\n",
       "        [ 5.12225237e-06],\n",
       "        [-6.68369353e-02],\n",
       "        [ 5.89767225e-02],\n",
       "        [-1.32636984e-02]]),\n",
       " array([[ 0.78374462,  1.0638874 ,  0.47257909,  0.59515403,  0.39969358,\n",
       "          0.37200897, -0.42478028,  0.26457151],\n",
       "        [ 0.91302903,  0.74845194,  0.87118199,  0.76607486,  0.76675793,\n",
       "          0.88750753,  0.95587759,  1.13524311],\n",
       "        [ 1.29153651,  1.41819833,  1.32442383,  1.43575227,  1.44800873,\n",
       "          1.4831545 ,  1.48568831,  1.71541832]]),\n",
       " array([0, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1,\n",
       "        2, 2, 1, 1, 2, 0, 0, 2]),\n",
       " None,\n",
       " 1014,\n",
       " np.float64(20.326500483282626))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @njit\n",
    "def _get_starting_values(y, x, G: int, N: int, K: int):\n",
    "    \"\"\"Generates the starting values of theta\"\"\"\n",
    "    num_start_vars: int = x.shape[1] + G # FIXME I believe that shape is slow in Cython\n",
    "    random_draws_theta = np.random.choice(N, num_start_vars, replace=False)\n",
    "    x_stack_start = x[random_draws_theta].reshape(-1, K)\n",
    "    y_stack_start = y[random_draws_theta].reshape(-1, 1)\n",
    "\n",
    "    # FIXME some errors may arise, maybe add some checks\n",
    "    theta_init = lstsq(x_stack_start, y_stack_start, rcond=None)[0]\n",
    "\n",
    "    random_draws_alpha = np.random.choice(N, size=G, replace=False)\n",
    "    alpha_init = np.squeeze(y[random_draws_alpha] - x[random_draws_alpha, :, :] @ theta_init)\n",
    "\n",
    "    return theta_init, alpha_init\n",
    "\n",
    "@njit\n",
    "def _compute_groupings(res, alpha):\n",
    "    \"\"\"Computes the groupings based on the residuals and alpha\"\"\"\n",
    "    euclidean_distance_between_grouping = ((res[None, :, :] - alpha[:, None, :]) ** 2).sum(axis=2)\n",
    "    g = np.argmin(euclidean_distance_between_grouping, axis=0)  # Closest group\n",
    "    return g\n",
    "\n",
    "# @njit\n",
    "def _compute_alpha(res, g, G):\n",
    "    \"\"\"Computes the alpha values based on the residuals and groupings\"\"\"\n",
    "    counts = np.bincount(g, minlength=G)[:, None]  # (G, 1) â€” number of elements in each group\n",
    "    sums = np.zeros((G, res.shape[1]))  # (G, K) â€” sum of residuals per group\n",
    "    np.add.at(sums, g, res)  # sums[i] += res[j] for all j where g[j] == i\n",
    "    alpha = sums / counts  # mean = sum / count\n",
    "    return alpha\n",
    "\n",
    "# @njit\n",
    "def _compute_theta(x, y, alpha, g):\n",
    "    \"\"\"Computes the theta values based on the x, y, alpha and groupings\"\"\"\n",
    "    # FIXME check if this makes sense\n",
    "    K = x.shape[2] # FIXME I believe that shape is slow in Cython\n",
    "    theta = lstsq(x.reshape(-1, K), y.reshape(-1, 1) - alpha[g].reshape(-1, 1), rcond=None)[0]\n",
    "    return theta\n",
    "\n",
    "# @njit\n",
    "def _compute_residuals(y, x, theta):\n",
    "    \"\"\"Computes the residuals based on y, x and theta\"\"\"\n",
    "    res = np.squeeze(y - x @ theta)\n",
    "    return res\n",
    "\n",
    "# @njit\n",
    "def _compute_objective_value(res, alpha, g):\n",
    "    \"\"\"Computes the objective value based on the residuals, alpha and groupings\"\"\"\n",
    "    # print(f\"res: {res}\")\n",
    "    # print(f\"alpha: {alpha}\")\n",
    "    # display(f\"g: {g}\")\n",
    "    # display(f\"alpha[g]: {alpha[g]}\")\n",
    "    objective_value = ((res - alpha[g])**2).sum()\n",
    "    return objective_value\n",
    "\n",
    "def _reorder_groups(g, alpha):\n",
    "    \"\"\"Reorders the groups based on the first value of alpha\"\"\"\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    mapping = np.argsort(alpha[:, 0])\n",
    "    ordered_g = np.argsort(mapping)[g]\n",
    "    ordered_alpha = alpha[mapping]\n",
    "    return ordered_g, ordered_alpha\n",
    "\n",
    "def _grouped_fixed_effects_iteration(y, x, G: int, N: int, K: int, max_iter=10000, tol=1e-8):\n",
    "    # FIXME possibly create some sort of array that stores these values\n",
    "    # Could be used for debugging\n",
    "    theta, alpha = _get_starting_values(y, x, G, N, K)\n",
    "    res = _compute_residuals(y, x, theta)\n",
    "    g = _compute_groupings(res, alpha)\n",
    "\n",
    "    objective_value = np.inf\n",
    "\n",
    "    iterations_used = 0\n",
    "    for i in range(max_iter):\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        theta = _compute_theta(x, y, alpha, g)\n",
    "        res = _compute_residuals(y, x, theta)\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        g = _compute_groupings(res, alpha)\n",
    "        new_objective_value = _compute_objective_value(res, alpha, g)\n",
    "\n",
    "\n",
    "        if abs(objective_value - new_objective_value) < tol:\n",
    "            iterations_used = i\n",
    "            objective_value = new_objective_value\n",
    "            break\n",
    "\n",
    "        objective_value = new_objective_value\n",
    "\n",
    "    return theta, alpha, g, iterations_used, objective_value\n",
    "\n",
    "def _compute_eta(y_bar, x_bar, theta):\n",
    "    \"\"\"Computes the eta values based on y_bar, x_bar and theta\"\"\"\n",
    "    eta = np.squeeze(y_bar - x_bar @ theta)\n",
    "    return eta\n",
    "\n",
    "# FIXME not used right now but still neccesary\n",
    "def _compute_statistics(objective_value, N, T, K, G):\n",
    "    \"\"\"Computes the statistics based on the objective value, N, T, K and G\"\"\"\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    sigma_squared = 1 / (N * T - G * T - N - K) * objective_value\n",
    "    BIC = 1/(N*T) * objective_value + sigma_squared * (G * T + N + K) / (N * T)\n",
    "    return sigma_squared, BIC\n",
    "\n",
    "\n",
    "def grouped_fixed_effects(y, x, G, max_iter=10000, tol=1e-8, gfe_iterations=20, unit_specific_effects=False):\n",
    "    \"\"\"\n",
    "    Computes the grouped fixed effects using the algorithm described in the paper.\n",
    "    \"\"\"\n",
    "    # FIXME not really required if unit_specific_effects is False\n",
    "    # But this seems like the easiest implementation\n",
    "    x_bar = np.mean(x, axis=1, keepdims=True)\n",
    "    y_bar = np.mean(y, axis=1, keepdims=True)\n",
    "\n",
    "    best_theta = None\n",
    "    best_alpha = None\n",
    "    best_g = None\n",
    "    best_iterations_used = None\n",
    "    best_objective_value = np.inf\n",
    "\n",
    "    N = x.shape[0]\n",
    "    K = x.shape[2]\n",
    "\n",
    "    # FIXME this code does not drop constant binary variables by itself\n",
    "    # The input class should be able to do this\n",
    "    if unit_specific_effects:\n",
    "        # Demean x and y\n",
    "        x = x - x_bar\n",
    "        y = y - y_bar\n",
    "\n",
    "    for _ in range(gfe_iterations):\n",
    "        theta, alpha, g, iterations_used, objective_value = _grouped_fixed_effects_iteration(\n",
    "            y,\n",
    "            x,\n",
    "            G,\n",
    "            N,\n",
    "            K,\n",
    "            max_iter,\n",
    "            tol,\n",
    "        )\n",
    "\n",
    "        if objective_value < best_objective_value:\n",
    "            best_objective_value = objective_value\n",
    "            best_theta = theta\n",
    "            best_g, best_alpha = _reorder_groups(g, alpha)\n",
    "            # best_g, best_alpha = g, alpha\n",
    "            best_iterations_used = iterations_used\n",
    "\n",
    "    if unit_specific_effects:\n",
    "        eta = _compute_eta(y_bar, x_bar, best_theta)\n",
    "        return best_theta, best_alpha, best_g, eta, best_iterations_used, best_objective_value\n",
    "\n",
    "    # NOTE None is for lack of unit specific effects\n",
    "    return best_theta, best_alpha, best_g, None, best_iterations_used, best_objective_value\n",
    "\n",
    "\n",
    "# FIXME Somewhere I have assumed that the sum of alpha is 0, this however does not have to be the case\n",
    "# I however do not know where and it may be for the computation of eta, in which case it is not a problem.\n",
    "grouped_fixed_effects(y[:30], x[:30], 3, max_iter=10000, tol=1e-8, gfe_iterations=100, unit_specific_effects=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d2ab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.57168978e-01],\n",
       "        [-4.40835523e-05],\n",
       "        [ 1.27102610e-01],\n",
       "        [ 1.62127299e-02],\n",
       "        [-6.39706245e-03]]),\n",
       " array([[0.97343144, 1.03654322, 0.88829947, 0.79455825, 0.71647648,\n",
       "         0.77282112, 0.58037268, 0.80762535],\n",
       "        [1.46456815, 1.43699556, 1.42924016, 1.45917693, 1.41420247,\n",
       "         1.37946067, 1.3035801 , 1.46244405]]),\n",
       " array([0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1]),\n",
       " None,\n",
       " 10,\n",
       " 27.718551774034854)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @njit\n",
    "def _get_starting_values(y, x, G: int, N: int, K: int):\n",
    "    \"\"\"Generates the starting values of theta\"\"\"\n",
    "    num_start_vars: int = x.shape[1] + G  # FIXME I believe that shape is slow in Cython\n",
    "    random_draws_theta = np.random.choice(N, num_start_vars, replace=False)\n",
    "    x_stack_start = x[random_draws_theta].reshape(-1, K)\n",
    "    y_stack_start = y[random_draws_theta].reshape(-1, 1)\n",
    "\n",
    "    # FIXME some errors may arise, maybe add some checks\n",
    "    theta_init = lstsq(x_stack_start, y_stack_start, rcond=None)[0]\n",
    "\n",
    "    random_draws_alpha = np.random.choice(N, size=G, replace=False)\n",
    "    alpha_init = np.squeeze(y[random_draws_alpha] - x[random_draws_alpha, :, :] @ theta_init)\n",
    "\n",
    "    return theta_init, alpha_init\n",
    "\n",
    "\n",
    "@njit\n",
    "def _compute_groupings(res, alpha):\n",
    "    \"\"\"Computes the groupings based on the residuals and alpha\"\"\"\n",
    "    euclidean_distance_between_grouping = ((res[None, :, :] - alpha[:, None, :]) ** 2).sum(axis=2)\n",
    "    g = np.argmin(euclidean_distance_between_grouping, axis=0)  # Closest group\n",
    "    return g\n",
    "\n",
    "\n",
    "# @njit\n",
    "def _compute_alpha(res, g, G):\n",
    "    \"\"\"Computes the alpha values based on the residuals and groupings\"\"\"\n",
    "    counts = np.bincount(g, minlength=G)[:, None]  # (G, 1) â€” number of elements in each group\n",
    "    sums = np.zeros((G, res.shape[1]))  # (G, K) â€” sum of residuals per group\n",
    "    np.add.at(sums, g, res)  # sums[i] += res[j] for all j where g[j] == i\n",
    "    alpha = sums / counts  # mean = sum / count\n",
    "    return alpha\n",
    "\n",
    "\n",
    "# @njit\n",
    "def _compute_theta(x, y, alpha, g):\n",
    "    \"\"\"Computes the theta values based on the x, y, alpha and groupings\"\"\"\n",
    "    # FIXME check if this makes sense\n",
    "    K = x.shape[2]  # FIXME I believe that shape is slow in Cython\n",
    "    theta = lstsq(x.reshape(-1, K), y.reshape(-1, 1) - alpha[g].reshape(-1, 1), rcond=None)[0]\n",
    "    return theta\n",
    "\n",
    "\n",
    "# @njit\n",
    "def _compute_residuals(y, x, theta):\n",
    "    \"\"\"Computes the residuals based on y, x and theta\"\"\"\n",
    "    res = np.squeeze(y - x @ theta)\n",
    "    return res\n",
    "\n",
    "\n",
    "@njit\n",
    "def _compute_objective_value(res, alpha, g):\n",
    "    \"\"\"Computes the objective value based on the residuals, alpha and groupings\"\"\"\n",
    "    objective_value = ((res - alpha[g]) ** 2).sum()\n",
    "    return objective_value\n",
    "\n",
    "\n",
    "def _reorder_groups(g, alpha):\n",
    "    \"\"\"Reorders the groups based on the first value of alpha\"\"\"\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    mapping = np.argsort(alpha[:, 0])\n",
    "    ordered_g = np.argsort(mapping)[g]\n",
    "    ordered_alpha = alpha[mapping]\n",
    "    return ordered_g, ordered_alpha\n",
    "\n",
    "def _hkmeans(y, x, theta, alpha, g, G, max_iter=1000, tol=1e-6):\n",
    "    objective_value = np.inf\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        res = _compute_residuals(y, x, theta)\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        theta = _compute_theta(x, y, alpha, g)\n",
    "        res = _compute_residuals(y, x, theta)\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        g = _compute_groupings(res, alpha)\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        new_objective_value = _compute_objective_value(res, alpha, g)\n",
    "\n",
    "        if abs(objective_value - new_objective_value) < tol:\n",
    "            return theta, alpha, g, i, new_objective_value\n",
    "\n",
    "        objective_value = new_objective_value\n",
    "\n",
    "    return theta, alpha, g, max_iter, objective_value\n",
    "\n",
    "\n",
    "def _run_vns(y, x, g, G, N, alpha, theta, init_objective_value, max_vns_iter=10, tol=1e-8, max_alg1_iter=20):\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    best_objective_value = init_objective_value\n",
    "    objective_value = np.inf\n",
    "    g = g.copy()\n",
    "\n",
    "\n",
    "    i = 1\n",
    "    while i <= max_vns_iter:\n",
    "        # Randomly change a few groupings\n",
    "        g_new = g.copy()\n",
    "\n",
    "        # FIXME this should check if there are empty groups\n",
    "        g_new[np.random.choice(N, size=i, replace=False)] = np.random.choice(G, size=i, replace=True)\n",
    "\n",
    "        # Apply algorithm 1\n",
    "        theta_new, alpha_new, g_new, iterations_used, objective_value = _hkmeans(y, x, theta, alpha, g_new, G)\n",
    "\n",
    "        # Local 1 step search\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for j in range(N):\n",
    "                for k in range(G):\n",
    "                    if g_new[j] == k:\n",
    "                        continue\n",
    "\n",
    "                    # FIXME add check to not leave any group empty\n",
    "\n",
    "                    g_local = g_new.copy()\n",
    "                    g_local[j] = k\n",
    "\n",
    "                    # FIXME this may be very slow\n",
    "                    if (np.bincount(g_local, minlength=G)==0).any():\n",
    "                        continue\n",
    "\n",
    "                    theta_local, alpha_local, g_local, iterations_used, objective_value_local = _hkmeans(y, x, theta_new, alpha_new, g_local, G, max_alg1_iter)\n",
    "\n",
    "                    if objective_value_local < objective_value:\n",
    "                        g_new = g_local\n",
    "                        theta_new = theta_local\n",
    "                        alpha_new = alpha_local\n",
    "                        objective_value = objective_value_local\n",
    "                        changed = True\n",
    "                        # print(f\"Changed group {j} to {k} in iteration {i} with objective value {objective_value}\")\n",
    "\n",
    "        if objective_value < best_objective_value:\n",
    "            g = g_new\n",
    "            theta = theta_new\n",
    "            alpha = alpha_new\n",
    "            best_objective_value = objective_value\n",
    "            i = 1\n",
    "\n",
    "        else:\n",
    "            i+= 1\n",
    "\n",
    "    return g, theta, alpha, objective_value\n",
    "\n",
    "\n",
    "def _grouped_fixed_effects_iteration_vns(y, x, G: int, N: int, K: int, max_iter=10000, tol=1e-8, neighbor_max=10):\n",
    "    # FIXME possibly create some sort of array that stores these values\n",
    "    # Could be used for debugging\n",
    "    theta, alpha = _get_starting_values(y, x, G, N, K)\n",
    "    res = _compute_residuals(y, x, theta)\n",
    "    g = _compute_groupings(res, alpha)\n",
    "\n",
    "    objective_value = np.inf\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        theta = _compute_theta(x, y, alpha, g)\n",
    "        res = _compute_residuals(y, x, theta)\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        g = _compute_groupings(res, alpha)\n",
    "        alpha = _compute_alpha(res, g, G)\n",
    "        new_objective_value = _compute_objective_value(res, alpha, g)\n",
    "\n",
    "        # TODO run VNS\n",
    "        g, theta, alpha, new_objective_value = _run_vns(y, x, g, G, N, alpha, theta, new_objective_value)\n",
    "\n",
    "        # if abs(objective_value - new_objective_value) < tol:\n",
    "        #     iterations_used = i\n",
    "        #     objective_value = new_objective_value\n",
    "        #     break\n",
    "\n",
    "        objective_value = new_objective_value\n",
    "\n",
    "    return theta, alpha, g, max_iter, objective_value\n",
    "\n",
    "\n",
    "def _compute_eta(y_bar, x_bar, theta):\n",
    "    \"\"\"Computes the eta values based on y_bar, x_bar and theta\"\"\"\n",
    "    eta = np.squeeze(y_bar - x_bar @ theta)\n",
    "    return eta\n",
    "\n",
    "\n",
    "# FIXME not used right now but still neccesary\n",
    "def _compute_statistics(objective_value, N, T, K, G):\n",
    "    \"\"\"Computes the statistics based on the objective value, N, T, K and G\"\"\"\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    sigma_squared = 1 / (N * T - G * T - N - K) * objective_value\n",
    "    BIC = 1 / (N * T) * objective_value + sigma_squared * (G * T + N + K) / (N * T)\n",
    "    return sigma_squared, BIC\n",
    "\n",
    "\n",
    "def grouped_fixed_effects(\n",
    "    y, x, G, max_iter=10000, tol=1e-8, gfe_iterations=20, unit_specific_effects=False, enable_vns=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the grouped fixed effects using the algorithm described in the paper.\n",
    "    \"\"\"\n",
    "    # FIXME not really required if unit_specific_effects is False\n",
    "    # But this seems like the easiest implementation\n",
    "    x_bar = np.mean(x, axis=1, keepdims=True)\n",
    "    y_bar = np.mean(y, axis=1, keepdims=True)\n",
    "\n",
    "    best_theta = None\n",
    "    best_alpha = None\n",
    "    best_g = None\n",
    "    best_iterations_used = None\n",
    "    best_objective_value = np.inf\n",
    "\n",
    "    N = x.shape[0]\n",
    "    K = x.shape[2]\n",
    "\n",
    "    # FIXME this code does not drop constant binary variables by itself\n",
    "    # The input class should be able to do this\n",
    "    if unit_specific_effects:\n",
    "        # Demean x and y\n",
    "        x = x - x_bar\n",
    "        y = y - y_bar\n",
    "\n",
    "    for _ in range(gfe_iterations):\n",
    "        if enable_vns:\n",
    "            theta, alpha, g, iterations_used, objective_value = _grouped_fixed_effects_iteration_vns(\n",
    "                y,\n",
    "                x,\n",
    "                G,\n",
    "                N,\n",
    "                K,\n",
    "                max_iter,\n",
    "                tol,\n",
    "            )\n",
    "        else:\n",
    "            theta, alpha, g, iterations_used, objective_value = _grouped_fixed_effects_iteration(\n",
    "                y,\n",
    "                x,\n",
    "                G,\n",
    "                N,\n",
    "                K,\n",
    "                max_iter,\n",
    "                tol,\n",
    "            )\n",
    "\n",
    "        if objective_value < best_objective_value:\n",
    "            best_objective_value = objective_value\n",
    "            best_theta = theta\n",
    "            best_g, best_alpha = _reorder_groups(g, alpha)\n",
    "            # best_g, best_alpha = g, alpha\n",
    "            best_iterations_used = iterations_used\n",
    "\n",
    "    if unit_specific_effects:\n",
    "        eta = _compute_eta(y_bar, x_bar, best_theta)\n",
    "        return best_theta, best_alpha, best_g, eta, best_iterations_used, best_objective_value\n",
    "\n",
    "    # NOTE None is for lack of unit specific effects\n",
    "    return best_theta, best_alpha, best_g, None, best_iterations_used, best_objective_value\n",
    "\n",
    "# FIXME tolerance is not relevant for VNS\n",
    "grouped_fixed_effects(y[0:30], x[0:30], 2, max_iter=10, tol=1e-8, gfe_iterations=1, unit_specific_effects=False, enable_vns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f976833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.22488343e-01],\n",
       "        [-1.42335696e-05],\n",
       "        [-5.81914823e-02],\n",
       "        [ 4.76984494e-02],\n",
       "        [-1.25956063e-02]]),\n",
       " array([[ 0.73126636,  0.89115714,  0.51139862,  0.61759711,  0.30741283,\n",
       "          0.24232603, -0.74638001, -0.00795854],\n",
       "        [ 0.92106121,  0.80920796,  0.79866353,  0.72195016,  0.70963451,\n",
       "          0.78703147,  0.82873625,  0.97793716],\n",
       "        [ 1.31643514,  1.42333681,  1.32876313,  1.38804703,  1.38068914,\n",
       "          1.40903594,  1.36407096,  1.60543939]]),\n",
       " array([0, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1,\n",
       "        2, 2, 1, 1, 2, 1, 0, 1]),\n",
       " None,\n",
       " 905,\n",
       " 20.43438978682646)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A practical rule of thumb for choosing the tuning parameters is to check that different starting values tend to yield the exact same solution. (from the paper)\n",
    "# grouped_fixed_effects(y[0:60], x[0:60], 3, max_iter=10000, tol=1e-8, gfe_iterations=100)\n",
    "grouped_fixed_effects(\n",
    "    y[0:30], x[0:30], 3, max_iter=1000, tol=1e-8, gfe_iterations=100, unit_specific_effects=False, enable_vns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff74bc",
   "metadata": {},
   "source": [
    "## Attempt at implementing Extension 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a76e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4.86008134e-01,  5.18001615e-02, -1.99441828e-01],\n",
       "        [-8.13075863e-05, -6.44077350e-05, -4.02078570e-04],\n",
       "        [ 6.01876007e-02,  1.51317580e-01, -2.49800181e-16],\n",
       "        [-7.58122222e-03, -3.00986592e-02,  4.56324210e-01],\n",
       "        [-2.62659555e-02, -3.83471825e-03, -3.16578091e-02]]),\n",
       " array([[ 0.33446786,  0.15809625, -0.10072759, -0.35208115, -0.47542558,\n",
       "         -0.4046256 , -0.37846026, -0.27071044],\n",
       "        [ 1.78426222,  1.84229201,  1.9234376 ,  2.0195686 ,  2.04513436,\n",
       "          2.07679585,  2.06409952,  2.28386173],\n",
       "        [ 2.39490207,  2.85697147,  3.34480934,  4.02789088,  4.48089238,\n",
       "          4.77309454,  4.08219583,  6.07411512]]),\n",
       " array([2, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 2, 1]),\n",
       " None,\n",
       " 0,\n",
       " 17.192112255108622)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @njit\n",
    "# FIXME remove this variable\n",
    "def _get_starting_values_hetrogeneous(y, x, G: int, N: int, K: int):\n",
    "    \"\"\"Generates the starting values of theta\"\"\"\n",
    "    num_start_vars: int = x.shape[1] + G  # FIXME I believe that shape is slow in Cython\n",
    "    random_draws_theta = np.random.choice(N, num_start_vars, replace=False)\n",
    "    x_stack_start = x[random_draws_theta].reshape(-1, K)\n",
    "    y_stack_start = y[random_draws_theta].reshape(-1, 1)\n",
    "\n",
    "    # FIXME some errors may arise, maybe add some checks\n",
    "    theta_init = lstsq(x_stack_start, y_stack_start, rcond=None)[0]\n",
    "\n",
    "    random_draws_alpha = np.random.choice(N, size=G, replace=False)\n",
    "    alpha_init = np.squeeze(y[random_draws_alpha] - x[random_draws_alpha, :, :] @ theta_init)\n",
    "\n",
    "    # FIXME this should be changed such that\n",
    "    return np.tile(theta_init, (1, G)), alpha_init\n",
    "\n",
    "# TODO create function for hetrogeneous theta\n",
    "\n",
    "\n",
    "# @njit\n",
    "def _compute_groupings_hetrogeneous(res, alpha):\n",
    "    \"\"\"Computes the groupings based on the residuals and alpha\"\"\"\n",
    "    euclidean_distance_between_grouping = np.squeeze((res - alpha.T[None, :, :]) ** 2).sum(axis=1)\n",
    "    g = np.argmin(euclidean_distance_between_grouping, axis=1)  # Closest group\n",
    "    return g\n",
    "\n",
    "\n",
    "# # @njit\n",
    "def _compute_alpha_hetrogeneous(res, g, G):\n",
    "    \"\"\"Computes the alpha values based on the residuals and groupings\"\"\"\n",
    "    n, T, _ = res.shape\n",
    "    counts = np.bincount(g, minlength=G)  # shape: (G,)\n",
    "    R = res[np.arange(n), :, g]  # shape: (n, T)\n",
    "    sums = np.zeros((G, T))\n",
    "    np.add.at(sums, g, R)  # sums[k] += R[i] whenever g[i]==k\n",
    "    alphas = sums / counts[:, None]  # broadcast counts over T\n",
    "    return alphas\n",
    "\n",
    "\n",
    "# # @njit\n",
    "def _compute_theta_hetrogeneous(x, y, alpha, g, G, K):\n",
    "    \"\"\"Computes the theta values based on the x, y, alpha and groupings\"\"\"\n",
    "    # FIXME check if this makes sense\n",
    "    theta = np.zeros((K, G))\n",
    "    for i in range(G):\n",
    "        theta[:, i] = lstsq(x[g==i].reshape(-1, K), np.squeeze((np.squeeze(y[g == i]) - alpha[i]).reshape(-1, 1)), rcond=None)[0]\n",
    "\n",
    "    return theta\n",
    "\n",
    "\n",
    "# # @njit\n",
    "def _compute_residuals_hetrogeneous(y, x, theta, G):\n",
    "    \"\"\"Computes the residuals based on y, x and theta\"\"\"\n",
    "    res = np.tile(y, (1, G)) - x @ theta\n",
    "    return res\n",
    "\n",
    "\n",
    "@njit\n",
    "def _compute_objective_value_hetrogeneous(res, alpha, g, N):\n",
    "    \"\"\"Computes the objective value based on the residuals, alpha and groupings\"\"\"\n",
    "    s = 0\n",
    "    for i in range(N):\n",
    "        s += ((res[i,:,g[i]] - alpha[g[i]]) ** 2).sum()\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def _reorder_groups_hetrogeneous(g, alpha, theta):\n",
    "    \"\"\"Reorders the groups based on the first value of alpha\"\"\"\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    mapping = np.argsort(alpha[:, 0])\n",
    "    ordered_g = np.argsort(mapping)[g]\n",
    "    ordered_alpha = alpha[mapping]\n",
    "    ordered_theta = theta[:, mapping]\n",
    "    return ordered_g, ordered_alpha, ordered_theta\n",
    "\n",
    "\n",
    "def _hkmeans_hetrogeneous(y, x, theta, alpha, g, G, K, N, max_iter=1000, tol=1e-6):\n",
    "    objective_value = np.inf\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        res = _compute_residuals_hetrogeneous(y, x, theta, G)\n",
    "        alpha = _compute_alpha_hetrogeneous(res, g, G)\n",
    "        theta = _compute_theta_hetrogeneous(x, y, alpha, g, G, K)\n",
    "        res = _compute_residuals_hetrogeneous(y, x, theta, G)\n",
    "        alpha = _compute_alpha_hetrogeneous(res, g, G)\n",
    "        g = _compute_groupings_hetrogeneous(res, alpha)\n",
    "        alpha = _compute_alpha_hetrogeneous(res, g, G)\n",
    "        new_objective_value = _compute_objective_value_hetrogeneous(res, alpha, g, N)\n",
    "\n",
    "        if abs(objective_value - new_objective_value) < tol:\n",
    "            return theta, alpha, g, i, new_objective_value\n",
    "\n",
    "        objective_value = new_objective_value\n",
    "\n",
    "    return theta, alpha, g, max_iter, objective_value\n",
    "\n",
    "\n",
    "def _run_vns_hetrogeneous(y, x, g, G, N, alpha, theta, init_objective_value, K, max_vns_iter=10, tol=1e-8, max_alg1_iter=20):\n",
    "    # FIXME this is not the best way to do this\n",
    "    # But it works for now\n",
    "    best_objective_value = init_objective_value\n",
    "    objective_value = np.inf\n",
    "    g = g.copy()\n",
    "\n",
    "    i = 1\n",
    "    while i <= max_vns_iter:\n",
    "        print(f\"vns iter: {i}\")\n",
    "        # Randomly change a few groupings\n",
    "        g_new = g.copy()\n",
    "\n",
    "        # FIXME this should check if there are empty groups\n",
    "        g_new[np.random.choice(N, size=i, replace=False)] = np.random.choice(G, size=i, replace=True)\n",
    "\n",
    "        # Apply algorithm 1\n",
    "        theta_new, alpha_new, g_new, iterations_used, objective_value = _hkmeans_hetrogeneous(\n",
    "            y, x, theta, alpha, g_new, G, K, N\n",
    "        )\n",
    "\n",
    "        # Local 1 step search\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for j in range(N):\n",
    "                for k in range(G):\n",
    "                    if g_new[j] == k:\n",
    "                        continue\n",
    "\n",
    "                    # FIXME add check to not leave any group empty\n",
    "\n",
    "                    g_local = g_new.copy()\n",
    "                    g_local[j] = k\n",
    "\n",
    "                    # FIXME this may be very slow\n",
    "                    if (np.bincount(g_local, minlength=G) == 0).any():\n",
    "                        continue\n",
    "\n",
    "                    theta_local, alpha_local, g_local, iterations_used, objective_value_local = _hkmeans_hetrogeneous(\n",
    "                        y, x, theta_new, alpha_new, g_local, G, K, N, max_alg1_iter\n",
    "                    )\n",
    "\n",
    "                    if objective_value_local < objective_value:\n",
    "                        g_new = g_local\n",
    "                        theta_new = theta_local\n",
    "                        alpha_new = alpha_local\n",
    "                        objective_value = objective_value_local\n",
    "                        changed = True\n",
    "                        # print(f\"Changed group {j} to {k} in iteration {i} with objective value {objective_value}\")\n",
    "\n",
    "        if objective_value < best_objective_value:\n",
    "            g = g_new\n",
    "            theta = theta_new\n",
    "            alpha = alpha_new\n",
    "            best_objective_value = objective_value\n",
    "            i = 1\n",
    "            print(f\"Succes at iteration {i} with objective value {best_objective_value}\")\n",
    "\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return g, theta, alpha, objective_value\n",
    "\n",
    "\n",
    "def _grouped_fixed_effects_iteration_vns_hetrogeneous(y, x, G: int, N: int, K: int, max_iter=10000, tol=1e-8, neighbor_max=10):\n",
    "    # FIXME possibly create some sort of array that stores these values\n",
    "    # Could be used for debugging\n",
    "    theta, alpha = _get_starting_values_hetrogeneous(y, x, G, N, K)\n",
    "    res = _compute_residuals_hetrogeneous(y, x, theta, G)\n",
    "    g = _compute_groupings_hetrogeneous(res, alpha)\n",
    "\n",
    "    objective_value = np.inf\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        print(f\"ITERATION: {i}\")\n",
    "        alpha = _compute_alpha_hetrogeneous(res, g, G)\n",
    "        theta = _compute_theta_hetrogeneous(x, y, alpha, g, G, K)\n",
    "        res = _compute_residuals_hetrogeneous(y, x, theta, G)\n",
    "        alpha = _compute_alpha_hetrogeneous(res, g, G)\n",
    "        g = _compute_groupings_hetrogeneous(res, alpha)\n",
    "        alpha = _compute_alpha_hetrogeneous(res, g, G)\n",
    "        new_objective_value = _compute_objective_value_hetrogeneous(res, alpha, g, N)\n",
    "\n",
    "        # TODO run VNS\n",
    "        g, theta, alpha, new_objective_value = _run_vns_hetrogeneous(y, x, g, G, N, alpha, theta, new_objective_value, K)\n",
    "\n",
    "        # if abs(objective_value - new_objective_value) < tol:\n",
    "        #     iterations_used = i\n",
    "        #     objective_value = new_objective_value\n",
    "        #     break\n",
    "\n",
    "        objective_value = new_objective_value\n",
    "\n",
    "    return theta, alpha, g, max_iter, objective_value\n",
    "\n",
    "\n",
    "def _grouped_fixed_effects_iteration_hetrogeneous(y, x, G: int, N: int, K: int, max_iter=10000, tol=1e-8):\n",
    "    # FIXME possibly create some sort of array that stores these values\n",
    "    # Could be used for debugging\n",
    "    theta, alpha = _get_starting_values_hetrogeneous(y, x, G, N, K)\n",
    "    res = _compute_residuals_hetrogeneous(y, x, theta, G)\n",
    "    g = _compute_groupings_hetrogeneous(res, alpha)\n",
    "\n",
    "    objective_value = np.inf\n",
    "\n",
    "    iterations_used = 0\n",
    "    for i in range(max_iter):\n",
    "        alpha = _compute_alpha_hetrogeneous(res, g, G)\n",
    "        theta = _compute_theta_hetrogeneous(x, y, alpha, g, G, K)\n",
    "        res = _compute_residuals_hetrogeneous(y, x, theta, G)\n",
    "        alpha = _compute_alpha_hetrogeneous(res, g, G)\n",
    "        g = _compute_groupings_hetrogeneous(res, alpha)\n",
    "        new_objective_value = _compute_objective_value_hetrogeneous(res, alpha, g, N)\n",
    "\n",
    "        if abs(objective_value - new_objective_value) < tol:\n",
    "            iterations_used = i\n",
    "            objective_value = new_objective_value\n",
    "            break\n",
    "\n",
    "        objective_value = new_objective_value\n",
    "\n",
    "    return theta, alpha, g, iterations_used, objective_value\n",
    "\n",
    "\n",
    "def _compute_eta_hetrogeneous(y_bar, x_bar, theta):\n",
    "    \"\"\"Computes the eta values based on y_bar, x_bar and theta\"\"\"\n",
    "    eta = np.squeeze(y_bar - x_bar @ theta.mean(axis=1))\n",
    "    return eta\n",
    "\n",
    "\n",
    "# # FIXME not used right now but still neccesary\n",
    "# def _compute_statistics(objective_value, N, T, K, G):\n",
    "#     \"\"\"Computes the statistics based on the objective value, N, T, K and G\"\"\"\n",
    "#     # FIXME this is not the best way to do this\n",
    "#     # But it works for now\n",
    "#     sigma_squared = 1 / (N * T - G * T - N - K) * objective_value\n",
    "#     BIC = 1 / (N * T) * objective_value + sigma_squared * (G * T + N + K) / (N * T)\n",
    "#     return sigma_squared, BIC\n",
    "\n",
    "\n",
    "def grouped_fixed_effects(\n",
    "    y, x, G, max_iter=10000, tol=1e-8, gfe_iterations=20, unit_specific_effects=False, enable_vns=True, hetrogeneous_theta=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the grouped fixed effects using the algorithm described in the paper.\n",
    "    \"\"\"\n",
    "    # FIXME not really required if unit_specific_effects is False\n",
    "    # But this seems like the easiest implementation\n",
    "    x_bar = np.mean(x, axis=1, keepdims=True)\n",
    "    y_bar = np.mean(y, axis=1, keepdims=True)\n",
    "\n",
    "    best_theta = None\n",
    "    best_alpha = None\n",
    "    best_g = None\n",
    "    best_iterations_used = None\n",
    "    best_objective_value = np.inf\n",
    "\n",
    "    N = x.shape[0]\n",
    "    T = x.shape[1]\n",
    "    K = x.shape[2]\n",
    "\n",
    "    # FIXME this code does not drop constant binary variables by itself\n",
    "    # The input class should be able to do this\n",
    "    if unit_specific_effects:\n",
    "        # Demean x and y\n",
    "        x = x - x_bar\n",
    "        y = y - y_bar\n",
    "\n",
    "    for _ in range(gfe_iterations):\n",
    "        # FIXME should be better way to do this\n",
    "        if hetrogeneous_theta and enable_vns:\n",
    "            theta, alpha, g, iterations_used, objective_value = _grouped_fixed_effects_iteration_vns_hetrogeneous(\n",
    "                y,\n",
    "                x,\n",
    "                G,\n",
    "                N,\n",
    "                K,\n",
    "                max_iter,\n",
    "                tol,\n",
    "            )\n",
    "        elif enable_vns:\n",
    "            theta, alpha, g, iterations_used, objective_value = _grouped_fixed_effects_iteration_vns(\n",
    "                y,\n",
    "                x,\n",
    "                G,\n",
    "                N,\n",
    "                K,\n",
    "                max_iter,\n",
    "                tol,\n",
    "            )\n",
    "\n",
    "        elif hetrogeneous_theta:\n",
    "            theta, alpha, g, iterations_used, objective_value = _grouped_fixed_effects_iteration_hetrogeneous(\n",
    "                y,\n",
    "                x,\n",
    "                G,\n",
    "                N,\n",
    "                K,\n",
    "                max_iter,\n",
    "                tol,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            theta, alpha, g, iterations_used, objective_value = _grouped_fixed_effects_iteration(\n",
    "                y,\n",
    "                x,\n",
    "                G,\n",
    "                N,\n",
    "                K,\n",
    "                max_iter,\n",
    "                tol\n",
    "            )\n",
    "\n",
    "        if objective_value < best_objective_value:\n",
    "            best_objective_value = objective_value\n",
    "            best_g, best_alpha, best_theta = _reorder_groups_hetrogeneous(g, alpha, theta)\n",
    "            # best_g, best_alpha = g, alpha\n",
    "            best_iterations_used = iterations_used\n",
    "\n",
    "    # FIXME this should not be true for hetrogeneous theta\n",
    "    # Because does not work\n",
    "    if unit_specific_effects:\n",
    "        eta = _compute_eta_hetrogeneous(y_bar, x_bar, best_theta)\n",
    "        return best_theta, best_alpha, best_g, eta, best_iterations_used, best_objective_value\n",
    "\n",
    "    # NOTE None is for lack of unit specific effects\n",
    "    return best_theta, best_alpha, best_g, None, best_iterations_used, best_objective_value\n",
    "\n",
    "\n",
    "# # FIXME tolerance is not relevant for VNS\n",
    "# FIXME for hetrogeneous theta VNS is super super slow\n",
    "grouped_fixed_effects(\n",
    "    y[0:30], x[0:30], 3, max_iter=1000, tol=0, gfe_iterations=100, unit_specific_effects=False, enable_vns=False, hetrogeneous_theta=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
