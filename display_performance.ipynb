{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc6813",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "14a2457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(true, estimate_file, dgp_file, bootstrap_iterations=200, g_true_index = -1):\n",
    "    with open(estimate_file, \"rb\") as f:\n",
    "        with open(dgp_file, \"rb\") as g:\n",
    "            data = pickle.load(g)\n",
    "            estimates = pickle.load(f)\n",
    "            results = []\n",
    "            for i, (e, d) in enumerate(zip(estimates, data)):\n",
    "                if e is None:\n",
    "                    continue\n",
    "                beta = e[\"params\"][\"beta\"]\n",
    "                g = e[\"params\"][\"g\"]\n",
    "                beta_analytical_se = e[\"analytical_se\"][\"beta\"]\n",
    "                conf_beta = e[\"analytical_conf_interval\"][\"beta\"]\n",
    "\n",
    "                bootstrap_se = e.get(\"bootstrap_se\")\n",
    "                beta_bootstrap_se = bootstrap_se.get(\"beta\") if isinstance(bootstrap_se, dict) else 0\n",
    "\n",
    "                bootstrap_conf = e.get(\"bootstrap_conf_interval\")\n",
    "                conf_beta_bootstrap = bootstrap_conf.get(\"beta\") if isinstance(bootstrap_conf, dict) else 0\n",
    "\n",
    "                fit_duration = e[\"fit_duration\"]\n",
    "\n",
    "                # Get same g\n",
    "                g_true = d[g_true_index]\n",
    "                g_est_size = len(g_true)\n",
    "                g_est = np.empty(g_est_size, dtype=np.int8)\n",
    "                for label, inds in g.items():\n",
    "                    g_est[inds] = label\n",
    "\n",
    "                # Get perc correct\n",
    "                perc_correct = np.mean(g_est == g_true)\n",
    "\n",
    "                # Get bias\n",
    "                bias = np.mean(beta - true)\n",
    "\n",
    "                # Get RMSE\n",
    "                mse = np.mean((beta - true) ** 2)\n",
    "\n",
    "                # Get confidence size\n",
    "                conf_size = (conf_beta[1] - conf_beta[0]).mean()\n",
    "                conf_size_bootstrap = 0\n",
    "\n",
    "                has_bootstrap = bootstrap_se is not None and bootstrap_se != 0\n",
    "                if has_bootstrap:\n",
    "                    fit_duration /= bootstrap_iterations\n",
    "\n",
    "                if conf_beta_bootstrap is not None and conf_beta_bootstrap != 0:\n",
    "                    conf_size_bootstrap = (conf_beta_bootstrap[1] - conf_beta_bootstrap[0]).mean()\n",
    "\n",
    "                # Get coverage\n",
    "                coverage = np.mean((true >= conf_beta[0]) & (true <= conf_beta[1]))\n",
    "                coverage_bootstrap = 0\n",
    "                if conf_beta_bootstrap is not None and conf_beta_bootstrap != 0:\n",
    "                    coverage_bootstrap = np.mean((true >= conf_beta_bootstrap[0]) & (true <= conf_beta_bootstrap[1]))\n",
    "\n",
    "                # Get mean se\n",
    "                mean_se = np.mean(beta_analytical_se)\n",
    "                mean_se_bootstrap = np.mean(beta_bootstrap_se)\n",
    "\n",
    "                results.append({\n",
    "                    \"perc_correct\": perc_correct,\n",
    "                    \"bias\": bias,\n",
    "                    \"mse\": mse,\n",
    "                    \"conf_size\": conf_size,\n",
    "                    \"conf_size_bootstrap\": conf_size_bootstrap,\n",
    "                    \"coverage\": coverage,\n",
    "                    \"coverage_bootstrap\": coverage_bootstrap,\n",
    "                    \"mean_se\": mean_se,\n",
    "                    \"mean_se_bootstrap\": mean_se_bootstrap,\n",
    "                    \"fit_duration\": fit_duration\n",
    "                })\n",
    "\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_means = results_df.mean()\n",
    "            results_means[\"rmse\"] = np.sqrt(results_means[\"mse\"])\n",
    "            return results_means.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b5add",
   "metadata": {},
   "source": [
    "# DGP1 (g=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "55892b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & perc_correct & bias & mse & conf_size & conf_size_bootstrap & coverage & coverage_bootstrap & mean_se & mean_se_bootstrap & fit_duration & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & 1.000 & 0.000 & 0.002 & 0.149 & 0.155 & 0.931 & 0.938 & 0.038 & 0.039 & 0.053 & 0.040 \\\\\n",
      "100 & 50 & 3 & 3 & 1.000 & -0.000 & 0.001 & 0.094 & 0.098 & 0.932 & 0.942 & 0.024 & 0.025 & 0.119 & 0.025 \\\\\n",
      "200 & 20 & 3 & 3 & 1.000 & -0.000 & 0.001 & 0.106 & 0.108 & 0.942 & 0.944 & 0.027 & 0.028 & 0.082 & 0.028 \\\\\n",
      "200 & 50 & 3 & 3 & 1.000 & -0.000 & 0.000 & 0.067 & 0.068 & 0.943 & 0.944 & 0.017 & 0.017 & 0.217 & 0.018 \\\\\n",
      "100 & 20 & 6 & 3 & 0.999 & -0.002 & 0.004 & 0.207 & 0.000 & 0.906 & 0.000 & 0.053 & 0.000 & 2.329 & 0.067 \\\\\n",
      "100 & 50 & 6 & 3 & 0.985 & 0.005 & 0.014 & 0.133 & 0.000 & 0.900 & 0.000 & 0.034 & 0.000 & 4.516 & 0.120 \\\\\n",
      "200 & 20 & 6 & 3 & 1.000 & 0.001 & 0.002 & 0.149 & 0.000 & 0.931 & 0.000 & 0.038 & 0.000 & 4.313 & 0.040 \\\\\n",
      "200 & 50 & 6 & 3 & 0.995 & 0.002 & 0.005 & 0.095 & 0.000 & 0.931 & 0.000 & 0.024 & 0.000 & 10.237 & 0.074 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{r}\n",
      "\\toprule\n",
      "rmse \\\\\n",
      "\\midrule\n",
      "0.040 \\\\\n",
      "0.025 \\\\\n",
      "0.028 \\\\\n",
      "0.018 \\\\\n",
      "0.067 \\\\\n",
      "0.120 \\\\\n",
      "0.040 \\\\\n",
      "0.074 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in (100, 200):\n",
    "    for t in (20, 50):\n",
    "        for g in (3, 6):\n",
    "            for k in (3,):\n",
    "                estimate_file = f\"estimates/dgp1_n{n}_t{t}_G{g}_k{k}_full.pkl\"\n",
    "                dgp_file = f\"development/generated_data/dgp1_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                true = np.array([[i, i, i] for i in range(1, g + 1)])\n",
    "\n",
    "                metrics = get_performance_metrics(true, estimate_file, dgp_file)\n",
    "\n",
    "                # Convert dict to DataFrame (assume keys are metric names, values are scalars or 1D)\n",
    "                row = dict(metrics)  # in case it's already a dict\n",
    "                row[\"n\"] = n\n",
    "                row[\"t\"] = t\n",
    "                row[\"G\"] = g\n",
    "                row[\"k\"] = k\n",
    "\n",
    "                results.append(row)\n",
    "\n",
    "# Now convert the list of dicts into a proper DataFrame\n",
    "final_results = pd.DataFrame(results)\n",
    "\n",
    "# Optional: reorder columns\n",
    "cols = [\"n\", \"t\", \"G\", \"k\"] + [col for col in final_results.columns if col not in [\"n\", \"t\", \"G\", \"k\"]]\n",
    "final_results = final_results[cols]\n",
    "print(final_results.round(3).sort_values(by=\"G\").to_latex(float_format=\"%.3f\", index=False, escape=False, column_format=\"l\" + \"r\" * (len(cols) - 1)))\n",
    "print(final_results[[\"G\", \"rmse\"]].round(3).sort_values(by=\"G\")[[\"rmse\"]].to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1669e2",
   "metadata": {},
   "source": [
    "## DGP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a648981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & perc_correct & bias & mse & conf_size & conf_size_bootstrap & coverage & coverage_bootstrap & mean_se & mean_se_bootstrap & fit_duration & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & 1.000 & -0.001 & 0.005 & 0.238 & 0.282 & 0.922 & 0.947 & 0.061 & 0.072 & 0.268 & 0.073 \\\\\n",
      "100 & 50 & 3 & 3 & 1.000 & 0.000 & 0.001 & 0.124 & 0.131 & 0.934 & 0.945 & 0.032 & 0.033 & 0.372 & 0.035 \\\\\n",
      "200 & 20 & 3 & 3 & 1.000 & 0.001 & 0.002 & 0.166 & 0.178 & 0.939 & 0.951 & 0.042 & 0.045 & 0.306 & 0.048 \\\\\n",
      "200 & 50 & 3 & 3 & 1.000 & -0.001 & 0.001 & 0.087 & 0.090 & 0.936 & 0.944 & 0.022 & 0.023 & 0.705 & 0.024 \\\\\n",
      "100 & 20 & 6 & 3 & 0.995 & 0.005 & 0.016 & 0.341 & 0.000 & 0.903 & 0.000 & 0.087 & 0.000 & 7.200 & 0.125 \\\\\n",
      "100 & 50 & 6 & 3 & 0.999 & 0.002 & 0.004 & 0.176 & 0.000 & 0.917 & 0.000 & 0.045 & 0.000 & 9.083 & 0.063 \\\\\n",
      "200 & 20 & 6 & 3 & 1.000 & -0.000 & 0.005 & 0.240 & 0.000 & 0.925 & 0.000 & 0.061 & 0.000 & 7.484 & 0.071 \\\\\n",
      "200 & 50 & 6 & 3 & 1.000 & -0.000 & 0.001 & 0.124 & 0.000 & 0.932 & 0.000 & 0.032 & 0.000 & 17.504 & 0.035 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{r}\n",
      "\\toprule\n",
      "rmse \\\\\n",
      "\\midrule\n",
      "0.073 \\\\\n",
      "0.035 \\\\\n",
      "0.048 \\\\\n",
      "0.024 \\\\\n",
      "0.125 \\\\\n",
      "0.063 \\\\\n",
      "0.071 \\\\\n",
      "0.035 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in (100, 200):\n",
    "    for t in (20, 50):\n",
    "        for g in (3, 6):\n",
    "            for k in (3,):\n",
    "                estimate_file = f\"estimates/dgp2_n{n}_t{t}_G{g}_k{k}_full.pkl\"\n",
    "                dgp_file = f\"development/generated_data/dgp2_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                true = np.array([[i, i, i] for i in range(1, g + 1)])\n",
    "\n",
    "                metrics = get_performance_metrics(true, estimate_file, dgp_file, g_true_index=3)\n",
    "\n",
    "                # Convert dict to DataFrame (assume keys are metric names, values are scalars or 1D)\n",
    "                row = dict(metrics)  # in case it's already a dict\n",
    "                row[\"n\"] = n\n",
    "                row[\"t\"] = t\n",
    "                row[\"G\"] = g\n",
    "                row[\"k\"] = k\n",
    "\n",
    "                results.append(row)\n",
    "\n",
    "# Now convert the list of dicts into a proper DataFrame\n",
    "final_results = pd.DataFrame(results)\n",
    "\n",
    "# Optional: reorder columns\n",
    "cols = [\"n\", \"t\", \"G\", \"k\"] + [col for col in final_results.columns if col not in [\"n\", \"t\", \"G\", \"k\"]]\n",
    "final_results = final_results[cols]\n",
    "print(final_results.round(3).sort_values(by=\"G\").to_latex(float_format=\"%.3f\", index=False, escape=False, column_format=\"l\" + \"r\" * (len(cols) - 1)))\n",
    "print(final_results[[\"G\", \"rmse\"]].round(3).sort_values(by=\"G\")[[\"rmse\"]].to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7902c4",
   "metadata": {},
   "source": [
    "## DGP2 (SJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0ac45e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & perc_correct & bias & mse & conf_size & conf_size_bootstrap & coverage & coverage_bootstrap & mean_se & mean_se_bootstrap & fit_duration & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & 0.996 & -0.002 & 0.004 & 0.176 & 0.000 & 0.816 & 0.000 & 0.045 & 0.000 & 0.981 & 0.065 \\\\\n",
      "100 & 50 & 3 & 3 & 1.000 & -0.001 & 0.001 & 0.102 & 0.000 & 0.899 & 0.000 & 0.026 & 0.000 & 2.795 & 0.031 \\\\\n",
      "200 & 20 & 3 & 3 & 0.997 & 0.001 & 0.003 & 0.122 & 0.000 & 0.761 & 0.000 & 0.031 & 0.000 & 2.421 & 0.057 \\\\\n",
      "200 & 50 & 3 & 3 & 1.000 & -0.000 & 0.001 & 0.071 & 0.000 & 0.861 & 0.000 & 0.018 & 0.000 & 6.649 & 0.024 \\\\\n",
      "100 & 20 & 6 & 3 & 0.942 & 0.003 & 0.064 & 0.345 & 0.000 & 0.630 & 0.000 & 0.088 & 0.000 & 1.896 & 0.253 \\\\\n",
      "100 & 50 & 6 & 3 & 0.981 & 0.001 & 0.032 & 0.192 & 0.000 & 0.712 & 0.000 & 0.049 & 0.000 & 5.286 & 0.178 \\\\\n",
      "200 & 20 & 6 & 3 & 0.963 & -0.001 & 0.040 & 0.230 & 0.000 & 0.539 & 0.000 & 0.059 & 0.000 & 5.272 & 0.201 \\\\\n",
      "200 & 50 & 6 & 3 & 0.996 & 0.004 & 0.009 & 0.113 & 0.000 & 0.671 & 0.000 & 0.029 & 0.000 & 13.169 & 0.092 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{r}\n",
      "\\toprule\n",
      "rmse \\\\\n",
      "\\midrule\n",
      "0.065 \\\\\n",
      "0.031 \\\\\n",
      "0.057 \\\\\n",
      "0.024 \\\\\n",
      "0.253 \\\\\n",
      "0.178 \\\\\n",
      "0.201 \\\\\n",
      "0.092 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in (100, 200):\n",
    "    for t in (20, 50):\n",
    "        for g in (3, 6):\n",
    "            for k in (3,):\n",
    "                estimate_file = f\"estimates/dgp2_n{n}_t{t}_G{g}_k{k}_su_ju.pkl\"\n",
    "                dgp_file = f\"development/generated_data/dgp2_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                true = np.array([[i, i, i] for i in range(1, g + 1)])\n",
    "\n",
    "                metrics = get_performance_metrics(true, estimate_file, dgp_file, g_true_index=3)\n",
    "\n",
    "                # Convert dict to DataFrame (assume keys are metric names, values are scalars or 1D)\n",
    "                row = dict(metrics)  # in case it's already a dict\n",
    "                row[\"n\"] = n\n",
    "                row[\"t\"] = t\n",
    "                row[\"G\"] = g\n",
    "                row[\"k\"] = k\n",
    "\n",
    "                results.append(row)\n",
    "\n",
    "# Now convert the list of dicts into a proper DataFrame\n",
    "final_results = pd.DataFrame(results)\n",
    "\n",
    "# Optional: reorder columns\n",
    "cols = [\"n\", \"t\", \"G\", \"k\"] + [col for col in final_results.columns if col not in [\"n\", \"t\", \"G\", \"k\"]]\n",
    "final_results = final_results[cols]\n",
    "print(\n",
    "    final_results.round(3)\n",
    "    .sort_values(by=\"G\")\n",
    "    .to_latex(float_format=\"%.3f\", index=False, escape=False, column_format=\"l\" + \"r\" * (len(cols) - 1))\n",
    ")\n",
    "print(final_results[[\"G\", \"rmse\"]].round(3).sort_values(by=\"G\")[[\"rmse\"]].to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "81873ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & perc_correct & bias & mse & conf_size & conf_size_bootstrap & coverage & coverage_bootstrap & mean_se & mean_se_bootstrap & fit_duration & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & 0.995 & -0.003 & 0.007 & 0.023 & 0.285 & 0.124 & 0.939 & 0.006 & 0.073 & 0.427 & 0.086 \\\\\n",
      "100 & 50 & 3 & 3 & 1.000 & -0.001 & 0.001 & 0.017 & 0.133 & 0.198 & 0.956 & 0.004 & 0.034 & 0.929 & 0.031 \\\\\n",
      "200 & 20 & 3 & 3 & 0.997 & 0.001 & 0.003 & 0.012 & 0.163 & 0.083 & 0.867 & 0.003 & 0.041 & 1.138 & 0.051 \\\\\n",
      "200 & 50 & 3 & 3 & 1.000 & -0.001 & 0.001 & 0.009 & 0.088 & 0.139 & 0.920 & 0.002 & 0.022 & 2.609 & 0.024 \\\\\n",
      "100 & 20 & 6 & 3 & 0.945 & 0.006 & 0.061 & 0.045 & 0.000 & 0.113 & 0.000 & 0.011 & 0.000 & 1.902 & 0.247 \\\\\n",
      "100 & 50 & 6 & 3 & 0.977 & 0.009 & 0.039 & 0.035 & 0.000 & 0.204 & 0.000 & 0.009 & 0.000 & 5.349 & 0.196 \\\\\n",
      "200 & 20 & 6 & 3 & 0.965 & 0.001 & 0.037 & 0.023 & 0.000 & 0.075 & 0.000 & 0.006 & 0.000 & 5.299 & 0.192 \\\\\n",
      "200 & 50 & 6 & 3 & 0.999 & -0.000 & 0.009 & 0.018 & 0.000 & 0.161 & 0.000 & 0.005 & 0.000 & 13.520 & 0.093 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{r}\n",
      "\\toprule\n",
      "rmse \\\\\n",
      "\\midrule\n",
      "0.086 \\\\\n",
      "0.031 \\\\\n",
      "0.051 \\\\\n",
      "0.024 \\\\\n",
      "0.247 \\\\\n",
      "0.196 \\\\\n",
      "0.192 \\\\\n",
      "0.093 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in (100, 200):\n",
    "    for t in (20, 50):\n",
    "        for g in (3, 6):\n",
    "            for k in (3,):\n",
    "                estimate_file = f\"estimates/old/dgp2_n{n}_t{t}_G{g}_k{k}_su_ju.pkl\"\n",
    "                dgp_file = f\"development/generated_data/dgp2_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                true = np.array([[i, i, i] for i in range(1, g + 1)])\n",
    "\n",
    "                metrics = get_performance_metrics(true, estimate_file, dgp_file, g_true_index=3)\n",
    "\n",
    "                # Convert dict to DataFrame (assume keys are metric names, values are scalars or 1D)\n",
    "                row = dict(metrics)  # in case it's already a dict\n",
    "                row[\"n\"] = n\n",
    "                row[\"t\"] = t\n",
    "                row[\"G\"] = g\n",
    "                row[\"k\"] = k\n",
    "\n",
    "                results.append(row)\n",
    "\n",
    "# Now convert the list of dicts into a proper DataFrame\n",
    "final_results = pd.DataFrame(results)\n",
    "\n",
    "# Optional: reorder columns\n",
    "cols = [\"n\", \"t\", \"G\", \"k\"] + [col for col in final_results.columns if col not in [\"n\", \"t\", \"G\", \"k\"]]\n",
    "final_results = final_results[cols]\n",
    "print(\n",
    "    final_results.round(3)\n",
    "    .sort_values(by=\"G\")\n",
    "    .to_latex(float_format=\"%.3f\", index=False, escape=False, column_format=\"l\" + \"r\" * (len(cols) - 1))\n",
    ")\n",
    "print(final_results[[\"G\", \"rmse\"]].round(3).sort_values(by=\"G\")[[\"rmse\"]].to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d191e7",
   "metadata": {},
   "source": [
    "## DGP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ad3083c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & perc_correct & bias & mse & conf_size & conf_size_bootstrap & coverage & coverage_bootstrap & mean_se & mean_se_bootstrap & fit_duration & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & 0.999 & -0.001 & 0.003 & 0.156 & 0.000 & 0.845 & 0.000 & 0.040 & 0.000 & 0.952 & 0.055 \\\\\n",
      "100 & 50 & 3 & 3 & 1.000 & -0.000 & 0.001 & 0.097 & 0.000 & 0.892 & 0.000 & 0.025 & 0.000 & 2.184 & 0.030 \\\\\n",
      "200 & 20 & 3 & 3 & 0.999 & -0.000 & 0.002 & 0.109 & 0.000 & 0.796 & 0.000 & 0.028 & 0.000 & 2.971 & 0.043 \\\\\n",
      "200 & 50 & 3 & 3 & 1.000 & 0.001 & 0.000 & 0.068 & 0.000 & 0.877 & 0.000 & 0.017 & 0.000 & 7.189 & 0.022 \\\\\n",
      "100 & 20 & 6 & 3 & 0.982 & -0.002 & 0.029 & 0.259 & 0.000 & 0.701 & 0.000 & 0.066 & 0.000 & 2.167 & 0.169 \\\\\n",
      "100 & 50 & 6 & 3 & 0.999 & 0.002 & 0.005 & 0.149 & 0.000 & 0.794 & 0.000 & 0.038 & 0.000 & 4.526 & 0.073 \\\\\n",
      "200 & 20 & 6 & 3 & 0.991 & -0.008 & 0.017 & 0.175 & 0.000 & 0.573 & 0.000 & 0.045 & 0.000 & 9.444 & 0.130 \\\\\n",
      "200 & 50 & 6 & 3 & 1.000 & -0.001 & 0.002 & 0.101 & 0.000 & 0.705 & 0.000 & 0.026 & 0.000 & 16.441 & 0.049 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in (100, 200):\n",
    "    for t in (20, 50):\n",
    "        for g in (3, 6):\n",
    "            for k in (3,):\n",
    "                estimate_file = f\"estimates/dgp3_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                dgp_file = f\"development/generated_data/dgp3_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                true = np.array([[i, i, i] for i in range(1, g + 1)])\n",
    "\n",
    "                metrics = get_performance_metrics(true, estimate_file, dgp_file, g_true_index=2)\n",
    "\n",
    "                # Convert dict to DataFrame (assume keys are metric names, values are scalars or 1D)\n",
    "                row = dict(metrics)  # in case it's already a dict\n",
    "                row[\"n\"] = n\n",
    "                row[\"t\"] = t\n",
    "                row[\"G\"] = g\n",
    "                row[\"k\"] = k\n",
    "\n",
    "                results.append(row)\n",
    "\n",
    "# Now convert the list of dicts into a proper DataFrame\n",
    "final_results = pd.DataFrame(results)\n",
    "\n",
    "# Optional: reorder columns\n",
    "cols = [\"n\", \"t\", \"G\", \"k\"] + [col for col in final_results.columns if col not in [\"n\", \"t\", \"G\", \"k\"]]\n",
    "final_results = final_results[cols]\n",
    "print(\n",
    "    final_results.round(3)\n",
    "    .sort_values(by=\"G\")\n",
    "    .to_latex(float_format=\"%.3f\", index=False, escape=False, column_format=\"l\" + \"r\" * (len(cols) - 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "77c49995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & perc_correct & bias & mse & conf_size & conf_size_bootstrap & coverage & coverage_bootstrap & mean_se & mean_se_bootstrap & fit_duration & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & 0.999 & -0.001 & 0.003 & 0.026 & 0.196 & 0.182 & 0.916 & 0.007 & 0.050 & 0.309 & 0.055 \\\\\n",
      "100 & 50 & 3 & 3 & 1.000 & -0.000 & 0.001 & 0.017 & 0.113 & 0.223 & 0.935 & 0.004 & 0.029 & 0.589 & 0.030 \\\\\n",
      "200 & 20 & 3 & 3 & 0.999 & -0.000 & 0.002 & 0.013 & 0.133 & 0.110 & 0.874 & 0.003 & 0.034 & 1.159 & 0.043 \\\\\n",
      "200 & 50 & 3 & 3 & 1.000 & 0.001 & 0.000 & 0.009 & 0.078 & 0.154 & 0.908 & 0.002 & 0.020 & 2.284 & 0.022 \\\\\n",
      "100 & 20 & 6 & 3 & 0.985 & 0.000 & 0.026 & 0.055 & 0.000 & 0.201 & 0.000 & 0.014 & 0.000 & 2.107 & 0.163 \\\\\n",
      "100 & 50 & 6 & 3 & 0.997 & -0.001 & 0.007 & 0.038 & 0.000 & 0.268 & 0.000 & 0.010 & 0.000 & 7.294 & 0.082 \\\\\n",
      "200 & 20 & 6 & 3 & 0.992 & -0.008 & 0.017 & 0.028 & 0.000 & 0.126 & 0.000 & 0.007 & 0.000 & 7.512 & 0.131 \\\\\n",
      "200 & 50 & 6 & 3 & 1.000 & -0.001 & 0.003 & 0.020 & 0.000 & 0.182 & 0.000 & 0.005 & 0.000 & 16.426 & 0.055 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{r}\n",
      "\\toprule\n",
      "rmse \\\\\n",
      "\\midrule\n",
      "0.055 \\\\\n",
      "0.030 \\\\\n",
      "0.043 \\\\\n",
      "0.022 \\\\\n",
      "0.163 \\\\\n",
      "0.082 \\\\\n",
      "0.131 \\\\\n",
      "0.055 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in (100, 200):\n",
    "    for t in (20, 50):\n",
    "        for g in (3, 6):\n",
    "            for k in (3,):\n",
    "                estimate_file = f\"estimates/old/dgp3_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                dgp_file = f\"development/generated_data/dgp3_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                true = np.array([[i, i, i] for i in range(1, g + 1)])\n",
    "\n",
    "                metrics = get_performance_metrics(true, estimate_file, dgp_file, g_true_index=2)\n",
    "\n",
    "                # Convert dict to DataFrame (assume keys are metric names, values are scalars or 1D)\n",
    "                row = dict(metrics)  # in case it's already a dict\n",
    "                row[\"n\"] = n\n",
    "                row[\"t\"] = t\n",
    "                row[\"G\"] = g\n",
    "                row[\"k\"] = k\n",
    "\n",
    "                results.append(row)\n",
    "\n",
    "# Now convert the list of dicts into a proper DataFrame\n",
    "final_results = pd.DataFrame(results)\n",
    "\n",
    "# Optional: reorder columns\n",
    "cols = [\"n\", \"t\", \"G\", \"k\"] + [col for col in final_results.columns if col not in [\"n\", \"t\", \"G\", \"k\"]]\n",
    "final_results = final_results[cols]\n",
    "print(\n",
    "    final_results.round(3)\n",
    "    .sort_values(by=\"G\")\n",
    "    .to_latex(float_format=\"%.3f\", index=False, escape=False, column_format=\"l\" + \"r\" * (len(cols) - 1))\n",
    ")\n",
    "print(final_results[[\"G\", \"rmse\"]].round(3).sort_values(by=\"G\")[[\"rmse\"]].to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593c9bb",
   "metadata": {},
   "source": [
    "## DGP1, 2, 3 Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9080fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics_alt(true, estimate_file, dgp_file, bootstrap_iterations=200, g_true_index=-1):\n",
    "    with open(dgp_file, \"rb\") as g:\n",
    "        with open(estimate_file, \"rb\") as f:\n",
    "            data = pickle.load(g)\n",
    "            estimates = pickle.load(f)\n",
    "            results = []\n",
    "            for i, (e, d) in enumerate(zip(estimates, data)):\n",
    "                # display(e)\n",
    "                beta = e[0]\n",
    "                beta_analytical_se = e[2]\n",
    "                conf_beta = e[1]\n",
    "\n",
    "                # Get bias\n",
    "                g_true = d[g_true_index]\n",
    "                bias = np.mean(beta - true[g_true])\n",
    "                # Get RMSE\n",
    "                mse = np.mean((beta - true[g_true]) ** 2)\n",
    "                # Get confidence size\n",
    "                conf_size = (conf_beta[:, :, 1] - conf_beta[:, :, 0]).mean()\n",
    "                # Get coverage\n",
    "                coverage = np.mean((true[g_true] >= conf_beta[:, :, 0]) & (true[g_true] <= conf_beta[:, :, 1]))\n",
    "                # Get mean se\n",
    "                mean_se = np.mean(beta_analytical_se)\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"bias\": bias,\n",
    "                        \"mse\": mse,\n",
    "                        \"conf_size\": conf_size,\n",
    "                        \"coverage\": coverage,\n",
    "                        \"mean_se\": mean_se,\n",
    "                    }\n",
    "                )\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_means = results_df.mean()\n",
    "            results_means[\"rmse\"] = np.sqrt(results_means[\"mse\"])\n",
    "            results_means.drop(columns=[\"mse\"], inplace=True)\n",
    "            return results_means.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "10193929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGP 1\n",
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & bias & mse & conf_size & coverage & mean_se & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & 0.001 & 0.181 & 1.727 & 0.950 & 0.408 & 0.425 \\\\\n",
      "100 & 50 & 3 & 3 & -0.001 & 0.072 & 1.062 & 0.952 & 0.264 & 0.269 \\\\\n",
      "200 & 20 & 3 & 3 & -0.001 & 0.186 & 1.751 & 0.950 & 0.413 & 0.431 \\\\\n",
      "200 & 50 & 3 & 3 & 0.001 & 0.073 & 1.068 & 0.950 & 0.265 & 0.270 \\\\\n",
      "100 & 20 & 6 & 3 & -0.001 & 0.180 & 1.730 & 0.952 & 0.408 & 0.425 \\\\\n",
      "100 & 50 & 6 & 3 & 0.000 & 0.073 & 1.064 & 0.949 & 0.264 & 0.270 \\\\\n",
      "200 & 20 & 6 & 3 & 0.002 & 0.185 & 1.747 & 0.950 & 0.412 & 0.430 \\\\\n",
      "200 & 50 & 6 & 3 & -0.000 & 0.074 & 1.071 & 0.950 & 0.266 & 0.271 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "DGP 2\n",
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & bias & mse & conf_size & coverage & mean_se & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & 0.001 & 0.875 & 3.619 & 0.950 & 0.854 & 0.936 \\\\\n",
      "100 & 50 & 3 & 3 & -0.001 & 0.312 & 2.102 & 0.951 & 0.522 & 0.559 \\\\\n",
      "200 & 20 & 3 & 3 & -0.001 & 0.886 & 3.633 & 0.950 & 0.856 & 0.941 \\\\\n",
      "200 & 50 & 3 & 3 & -0.000 & 0.316 & 2.110 & 0.950 & 0.524 & 0.562 \\\\\n",
      "100 & 20 & 6 & 3 & -0.002 & 0.878 & 3.621 & 0.951 & 0.854 & 0.937 \\\\\n",
      "100 & 50 & 6 & 3 & -0.001 & 0.316 & 2.107 & 0.951 & 0.523 & 0.562 \\\\\n",
      "200 & 20 & 6 & 3 & -0.003 & 0.882 & 3.624 & 0.949 & 0.855 & 0.939 \\\\\n",
      "200 & 50 & 6 & 3 & 0.000 & 0.315 & 2.107 & 0.950 & 0.523 & 0.561 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "DGP 3\n",
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "n & t & G & k & bias & mse & conf_size & coverage & mean_se & rmse \\\\\n",
      "\\midrule\n",
      "100 & 20 & 3 & 3 & -0.000 & 0.067 & 1.062 & 0.949 & 0.250 & 0.259 \\\\\n",
      "100 & 50 & 3 & 3 & -0.001 & 0.022 & 0.594 & 0.950 & 0.148 & 0.149 \\\\\n",
      "200 & 20 & 3 & 3 & 0.000 & 0.067 & 1.060 & 0.950 & 0.250 & 0.259 \\\\\n",
      "200 & 50 & 3 & 3 & 0.000 & 0.022 & 0.593 & 0.950 & 0.147 & 0.149 \\\\\n",
      "100 & 20 & 6 & 3 & -0.000 & 0.067 & 1.061 & 0.951 & 0.250 & 0.258 \\\\\n",
      "100 & 50 & 6 & 3 & 0.000 & 0.022 & 0.593 & 0.950 & 0.147 & 0.149 \\\\\n",
      "200 & 20 & 6 & 3 & -0.000 & 0.067 & 1.060 & 0.951 & 0.250 & 0.258 \\\\\n",
      "200 & 50 & 6 & 3 & -0.000 & 0.022 & 0.594 & 0.949 & 0.147 & 0.149 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dgp in (1, 2, 3):\n",
    "    results = []\n",
    "    for n in (100, 200):\n",
    "        for t in (20, 50):\n",
    "            for g in (3, 6):\n",
    "                for k in (3,):\n",
    "                    estimate_file = f\"estimates/dgp{dgp}_n{n}_t{t}_G{g}_k{k}_ols.pkl\"\n",
    "                    dgp_file = f\"development/generated_data/dgp{dgp}_n{n}_t{t}_G{g}_k{k}.pkl\"\n",
    "                    true = np.array([[i, i, i] for i in range(1, g + 1)])\n",
    "\n",
    "                    g_true_index = -1 if dgp == 1 else 3 if dgp == 2 else 2\n",
    "\n",
    "                    metrics = get_performance_metrics_alt(true, estimate_file, dgp_file, g_true_index=g_true_index)\n",
    "\n",
    "                    # Convert dict to DataFrame (assume keys are metric names, values are scalars or 1D)\n",
    "                    row = dict(metrics)  # in case it's already a dict\n",
    "                    row[\"n\"] = n\n",
    "                    row[\"t\"] = t\n",
    "                    row[\"G\"] = g\n",
    "                    row[\"k\"] = k\n",
    "\n",
    "                    results.append(row)\n",
    "\n",
    "    # Now convert the list of dicts into a proper DataFrame\n",
    "    final_results = pd.DataFrame(results)\n",
    "\n",
    "    # Optional: reorder columns\n",
    "    cols = [\"n\", \"t\", \"G\", \"k\"] + [col for col in final_results.columns if col not in [\"n\", \"t\", \"G\", \"k\"]]\n",
    "    final_results = final_results[cols]\n",
    "    print(f\"DGP {dgp}\")\n",
    "    print(\n",
    "        final_results.round(3)\n",
    "        .sort_values(by=\"G\")\n",
    "        .to_latex(float_format=\"%.3f\", index=False, escape=False, column_format=\"l\" + \"r\" * (len(cols) - 1))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
